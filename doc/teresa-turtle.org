#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:{} arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: teresa-turtle
#+author: William Henney
#+email: whenney@gmail.com
#+language: en
#+select_tags: export
#+exclude_tags: noexport


* NGC 6210

** Basic data on NGC 6210
+ Coordinates
  + (RA, Dec) = (16 44 29.5195973292, +23 47 59.491267229) sexagesimal
  + (RA, Dec) = (251.122998321, 23.7998586853) degrees
+ Radial velocity: -35 km/s

** Weak lines in spectra
+ He II 6560.10
  + Clearly seen on slits that pass through core of nebula
  + Small velocity splitting of only +/- 10 km/s
+ C II 6578.15
  + Weaker than the He II, but extends to a bit larger radii
  + Slightly larger velocity splitting
  + Also has a night sky component
+ He I 5015.68
  + In the [O III] spectrum
  + I think this is really a line
  + But we also have some optical ghosts
    + 5002 - definitely a ghost
    + 4996

** Original data files
+ [[file:~/Dropbox/Papers/LL-Objects/NGC6210/]]


** Plan of action
+ [2/6] Follow what I did for the Owl Nebula
  1. [X] Add WCS to image+slits
  2. [X] Make a median image and then use it to get slit positions
  3. [ ] Flux calibration using the median image
  4. [ ] At same time find offsets along slit
  5. [ ] Add WCS info to PV images
  6. [ ] Construct spectral maps (with tetrablock algorithm)


** [2/2] Median image
CLOSED: [2019-05-28 Tue 08:56]
+ We need to add WCS info to all of them
  + [X] Use astrometry.net
+ Most are Ha + [N II] image + slit
+ ~spm165~ is just an image and is saturated
  + [ ] Fix it - it is wrapping around the integers to negative values, so we just have to add 65536 to the negative pixels
+ Some are [O III] images
+ Others are properly saturated, but one is deep enough to show the halo well
  + ~spm238~ although it has artefacts from the central star

*** DONE Astrometry of image+slit exposures
CLOSED: [2019-05-26 Sun 17:53]
**** First test with astrometry.net
+ Based on what I did with \sigma Ori in [[id:B5B60BC7-5392-4245-93D6-8D17A6B56E5E][WCS solution from command line astrometry.net tools]]
+ Need to find the right index files
  + ICRS coords: 251.1230, 23.7999
  + Annoyingly, this falls at boundary of HEALPIX tiles, so we need ~10~ and ~31~ for the small scales
  + I am just getting scales ~00~ \to ~04~, which covers 2 to 11 arcmin.  Since the FOV is only 5 arcmin, this should be more than enough
  + Downloading from http://data.astrometry.net/5000/
    + The ~00~ scales are the biggest and take 15 min each
  + Copied to [[file:~/Work/astrometry/data/][file:~/Work/astrometry/data/]]
  + What should plate scale be?
    + FOV is 6.5 arcmin from Meaburn:2003a
    + Image size is 1024 pixels in all that I looked at
    + 6.5 60 / 1024 = 0.381 so try the range 0.35 \to 0.4
  + Test command - run in Terminal for safety
    #+begin_src sh :dir ../data/imslit :eval no 
      D=~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015
      solve-field --ra 251.1230 --dec 23.7999 --radius 1.0 --scale-units arcsecperpix --scale-low 0.35 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' $D/spm0030o_b.fits 
    #+end_src
  + That worked, but it wrote output to Teresa's shared Dropbox folder
    + Fix it using ~--dir .~ option
    + Try again with ~0035~
    + That worked fine, although the alignment is not perfect
    + If this turns out to be a problem I could try one or more of the following
      1. [X] Use ~--no-tweak~ setting to avoid using SIP polynomial
         - *yes* - that worked much better
         - and there should not be much need for distortion correction since nebula is much smaller than CCD
         - We also need to add ~--overwrite~ option in order to re-do the same image
      2. Maybe increase ~--odds-to-solve~ (default 1e9)
      3. Maybe play with ~--code-tolerance~ or ~--pixel-error~ but I am not sure what these mean (need to read Lang:2010a more carefully).
**** Production run with astrometry.net
+ First, need to get a list of all the image+slit files
***** ~solve-astrometry-imslit.sh~
#+name: imslit-list-2015
+ spm0030
+ spm0035
+ spm0036
+ spm0041
+ spm0042
+ spm0047
+ spm0048
+ spm0053
+ spm0056
+ spm0061
+ spm0109
+ spm0114
+ spm0115
+ spm0120
+ spm0121
+ spm0123
+ spm0128
+ spm0172
+ spm0177
+ spm0178
+ spm0183
+ spm0185
+ spm0190

Note that we need to use the ~${var[*]}~ syntax to access whole of array

#+header: :var files=imslit-list-2015
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 1.0 --scale-units arcsecperpix --scale-low 0.35 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/${f}o_b.fits
  done
#+end_src
***** ~solve-astrometry-imslit-failed.sh~
Some of these did not solve - see [[file:astrometry-imslit-2015.log]]

#+name: imslit-failed-2015
+ 0053
+ 0061
+ 0128
+ 0183
+ 0190

What do these have in common?
****** Try again with some modifications

Reduce required odds from 1e9 to 1e6

#+header: :var files=imslit-failed-2015
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-failed.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 1.0 --scale-units arcsecperpix --scale-low 0.35 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/spm${f}o_b.fits --odds-to-solve 1e6
  done
#+end_src

Some of these succeeded this time, and the solutions are totally fine
+ [X] 0053
+ 0061
+ 0128
+ 0183
+ [X] 0190

Reduce required odds still further

+ [X] 0061 (worked with 1e3)
+ [X] 0183 (worked with 30)
+ [X] 0128 (finally with 15, and increasing ~code-tol~ from 0.01 to 0.03)


#+name: imslit-stubborn-2015
+ 0128

#+header: :var files=imslit-stubborn-2015
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-stubborn.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 0.1 --scale-units arcsecperpix --scale-low 0.35 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/spm${f}o_b.fits --odds-to-solve 15 --quad-size-min 0.03 --code-tol 0.03 -v
  done
#+end_src


****** Example of successful run
#+begin_example
  Reading input file 1 of 1: "/Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0030o_b.fits"...
  Extracting sources...
  simplexy: found 44 sources.
  Solving...
  system: No such file or directory
  engine.c:79:engine_autoindex_search_paths: Warning: failed to open index directory: "/usr/local/Cellar/astrometry-net/0.76_2/data"

  Reading file "./spm0030o_b.axy"...
  Only searching for solutions within 1 degrees of RA,Dec (251.123,23.7999)
    log-odds ratio 31.3066 (3.94724e+13), 19 match, 1 conflict, 20 distractors, 71 index.
    RA,Dec = (251.122,23.7979), pixel scale 0.35018 arcsec/pix.
    Hit/miss:   Hit/miss: -++++--+--+c---++--+-+--++-+----+-+++-++(best)++++
  Field 1: solved with index index-5000-10.fits.
  Field 1 solved: writing to file ./spm0030o_b.solved to indicate this.
  Field: /Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0030o_b.fits
  Field center: (RA,Dec) = (251.121851, 23.797830) deg.
  Field center: (RA H:M:S, Dec D:M:S) = (16:44:29.244, +23:47:52.188).
  Field size: 5.51533 x 5.92387 arcminutes
  Field rotation angle: up is -87.8426 degrees E of N
  Field parity: pos
  Creating new FITS file "./spm0030o_b-wcs.fits"...
  Creating index object overlay plot...
  Creating annotation plot...
  Your field contains:
    NGC 6210
#+end_example
****** Examples of failed runs
******* 0053
#+begin_example
  Reading input file 1 of 1: "/Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0053o_b.fits"...
  Extracting sources...
  simplexy: found 46 sources.
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:25: RuntimeWarning: divide by zero encountered in log
    logpoisson = k*np.log(mean) - mean - np.array([sum(np.arange(kk)) for kk in k])
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:25: RuntimeWarning: invalid value encountered in multiply
    logpoisson = k*np.log(mean) - mean - np.array([sum(np.arange(kk)) for kk in k])
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:26: RuntimeWarning: invalid value encountered in less
    badbins = occupied[logpoisson < logcut]
  Solving...
  system: No such file or directory
  engine.c:79:engine_autoindex_search_paths: Warning: failed to open index directory: "/usr/local/Cellar/astrometry-net/0.76_2/data"

  Reading file "./spm0053o_b.axy"...
  Only searching for solutions within 1 degrees of RA,Dec (251.123,23.7999)
  Field 1 did not solve (index index-5000-10.fits).
  Field: /Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0053o_b.fits
  Did not solve (or no WCS file was written).
#+end_example
******* 0061
#+begin_example
  Reading input file 1 of 1: "/Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0061o_b.fits"...
  Extracting sources...
  simplexy: found 51 sources.
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:25: RuntimeWarning: divide by zero encountered in log
    logpoisson = k*np.log(mean) - mean - np.array([sum(np.arange(kk)) for kk in k])
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:25: RuntimeWarning: invalid value encountered in multiply
    logpoisson = k*np.log(mean) - mean - np.array([sum(np.arange(kk)) for kk in k])
  /usr/local/Cellar/astrometry-net/0.76_2/libexec/lib/python3.7/site-packages/astrometry/util/removelines.py:26: RuntimeWarning: invalid value encountered in less
    badbins = occupied[logpoisson < logcut]
  Solving...
  system: No such file or directory
  engine.c:79:engine_autoindex_search_paths: Warning: failed to open index directory: "/usr/local/Cellar/astrometry-net/0.76_2/data"

  Reading file "./spm0061o_b.axy"...
  Only searching for solutions within 1 degrees of RA,Dec (251.123,23.7999)
  Field 1 did not solve (index index-5000-10.fits).
  Field: /Users/will/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/spm0061o_b.fits
  Did not solve (or no WCS file was written).
#+end_example
***** ~solve-astrometry-imslit-missing.sh~
And some were missing 

#+name: imslit-missing-2015
+ 0042
+ 0047

#+header: :var files=imslit-missing-2015
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-missing.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 1.0 --scale-units arcsecperpix --scale-low 0.35 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/spm${f}o_b.fits
  done
#+end_src

Missing ones now got from Tere, and they worked
***** ~solve-astrometry-imslit-varias.sh~

#+name: imslit-list-varias
+ obj1002_bcr 
+ obj1006_bcr 
+ obj1009_bcr 
+ obj1012_bcr 
+ obj1017_bcr 
+ spm110_u
+ spm115_bcr 
+ spm118_bcr 
+ spm121_bcr 
+ spm124_bcr 
+ spm127_bcr 
+ spm134_bcr 
+ spm165_bcr 
+ spm223_bcr 
+ spm229_bcr 
+ spm318_bcr 
+ spm328_bcr 
+ spm331_bcr 
+ spm414_bcr 
+ spm236_bcr 
+ spm238_bcr 
+ spm242_bcr 
+ spm251_bcr 
+ spm256_bcr 
+ spm293_bcr 
+ spm296_bcr 
+ spm302_bcr 
+ spm303_bcr 
+ spm305_bcr 
+ spm306_bcr 
+ spm350_bcr 
+ spm358_bcr 
+ spm407_bcr
+ spm111_bcr
+ spm116_bcr
+ spm003_b
+ spm004_b
+ spm017_b

These have 512x512 arrays, so image pixels are bigger.  Use all the loose tolerances from the start

#+header: :var files=imslit-list-varias
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-varias.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 0.1 --scale-units arcsecperpix --scale-low 0.5 --scale-high 0.8 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/${f}.fits --odds-to-solve 1e6 --quad-size-min 0.01 --code-tol 0.03
  done
#+end_src

Six failed with the more stringent limits.  Three we will try with looser limits

#+name: imslit-failed-varias
+ obj1002_bcr
+ obj1006_bcr
+ spm293_bcr
#+header: :var files=imslit-failed-varias
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-varias-failed.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 0.1 --scale-units arcsecperpix --scale-low 0.5 --scale-high 0.8 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/${f}.fits --odds-to-solve 1e3 --quad-size-min 0.01 --code-tol 0.03
  done
#+end_src


But with 4 it is because the plate scale is smaller
#+name: imslit-1024-varias
+ spm003_b
+ spm004_b
+ spm017_b
+ spm019_b
+ spm021_b
+ spm111_cr
#+header: :var files=imslit-1024-varias
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-varias-1024.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  for f in ${files[*]}; do
      solve-field --ra 251.1230 --dec 23.7999 --radius 0.1 --scale-units arcsecperpix --scale-low 0.3 --scale-high 0.4 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/${f}.fits --odds-to-solve 1e6 --quad-size-min 0.03 --code-tol 0.01
  done
#+end_src

+ [2019-06-04 Tue 18:20] Got extra file from Tere that was missing ~spm116-2~
  + I need to remove the bias myself
    + Measured to be median of 856
  + Also needed to remove cosmic rays in order for astrometry to work
    + All sorted now


Remove bias from file

#+begin_src python :results output :dir ~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  from astropy.io import fits
  hdulist = fits.open("spm116-2.fits")
  hdulist.info()
  hdu = hdulist[0]
  hdu.data = hdu.data.astype(float) - 856
  hdu.writeto("spm116-2_b.fits", overwrite=True)
#+end_src

#+RESULTS:
: Filename: spm116-2.fits
: No.    Name      Ver    Type      Cards   Dimensions   Format
:   0  PRIMARY       1 PrimaryHDU      30   (1076, 1024)   int16   

Remove cosmic rays 
#+begin_src python :results output :dir ~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  from astropy.io import fits
  from astroscrappy import detect_cosmics
  hdulist = fits.open("spm116-2_b.fits")
  hdulist.info()
  hdu = hdulist[0]
  mask, newdata = detect_cosmics(hdu.data)
  hdu.data = newdata
  hdu.writeto("spm116-2_bcr.fits", overwrite=True)
#+end_src

#+RESULTS:
: Filename: spm116-2_b.fits
: No.    Name      Ver    Type      Cards   Dimensions   Format
:   0  PRIMARY       1 PrimaryHDU      30   (1076, 1024)   float64   



#+name: imslit-missed
+ spm116-2_bcr
#+header: :var files=imslit-missed
#+begin_src sh :tangle ../scripts/solve-astrometry-imslit-varias-missed.sh :eval no
  D=~/Dropbox/Papers/LL-Objects/NGC6210/Varias-temporadas
  for f in ${files[*]}; do
      solve-field -v --ra 251.1230 --dec 23.7999 --radius 0.1 --scale-units arcsecperpix --scale-low 0.3 --scale-high 0.7 --dir . --new-fits '%s-wcs.fits' --no-tweak --overwrite $D/${f}.fits --odds-to-solve 1e2 --code-tol 0.03
  done
#+end_src

This finally worked

*** DONE Combining the image + slits
CLOSED: [2019-05-28 Tue 08:57]
+ We do this separately for [O III] and Ha+[N II]
+ [4/4] Steps
  1. [X] Make a common grid for all images
     + Try 0.3 arcsec pixels and 512x512
  2. [X] Then scale all to a common min/max
     - This and the previous step are done in [[id:4FA9561B-6694-4D6F-98DE-320EB1FEAB0E][Re-gridding images]]
     - We use the median of top-right corner (slice: [420:, 420:]) for the background
     - We use the median of the central 18x18 arcsec portion (slice: [230:290, 230:290]) for the normalization
     - Final pixel values range up to about 10
  3. [X] Calculate median image
     - This is done in [[id:E0D99541-C96F-4927-8809-7912F10CB724][Combining into median image and divide by it]]
  4. [X] And take ratio of each individual to the median
+ Unfortunately, although this worked, the results are not very pretty
  + It will be difficult to automatically find the slits
  + Maybe I should use Teresa's results (/no, not necessary - now I have found slit positions by hand/)
**** Re-gridding images
:PROPERTIES:
:ID:       4FA9561B-6694-4D6F-98DE-320EB1FEAB0E
:END:

This should be run from top-level folder

#+header: :var tab=pos-ha
#+begin_src python :tangle ../scripts/regrid-images-ha.py :colnames no 
  import numpy as np
  from scipy.interpolate import griddata
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.table import Table
  #
  # First set up WCS for the output image
  # We use capital letters for the output variables
  #

  NX, NY = 512, 512
  # 0.5 arcsec pixels
  dRA, dDec = -0.3/3600., 0.3/3600.
  # Center on central star of NGC 6210
  RA0, Dec0 = 251.122998321, 23.7998586853
  W = WCS(naxis=2)
  W.wcs.cdelt = [dRA, dDec]
  W.wcs.crpix = [0.5*(1 + NX), 0.5*(1 + NY)]
  W.wcs.crval = [RA0, Dec0]
  W.wcs.ctype = ['RA---TAN', 'DEC--TAN']

  outimage = np.zeros((NY, NX))
  # Create world coord arrays for output image
  II, JJ = np.meshgrid(np.arange(NX), np.arange(NY))
  RA, Dec = W.all_pix2world(II, JJ, 0)

  #
  # Read in the list of slits
  #
  table = Table(rows=tab[1:], names=tab[0])

  for i, row in enumerate(table):
      hdu, = fits.open(f"data/imslit/{row['imslit']}-wcs.fits")
      # image = (hdu.data - row['bias']) / (row['core'] - row['bias'])
      image = hdu.data
      outfilename = f'data/imslit-ha/imslit-{i:02d}.fits'
      ny, nx = image.shape
      #hdu.header.remove('@EPOCH')
      w = WCS(hdu.header)
      # Create world coord arrays for input image
      ii, jj = np.meshgrid(np.arange(nx), np.arange(ny))
      ra, dec = w.all_pix2world(ii, jj, 0)
      # Do the interpolation
      points = np.array(list(zip(ra.ravel(), dec.ravel())))
      xi = np.array(list(zip(RA.ravel(), Dec.ravel())))
      outimage = griddata(points, image.ravel(), xi, method='nearest').reshape((NY, NX))
      bg = np.nanmedian(outimage[420:, 420:])
      core = np.nanmedian(outimage[230:290, 230:290])
      print(core, bg)
      outimage = (outimage - bg)/(core - bg)
      # Save the output image
      fits.PrimaryHDU(header=W.to_header(), data=outimage).writeto(outfilename, overwrite=True)




#+end_src


#+header: :var tab=pos-oiii
#+begin_src python :tangle ../scripts/regrid-images-oiii.py :colnames no 
  import numpy as np
  from scipy.interpolate import griddata
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.table import Table


  #
  # First set up WCS for the output image
  # We use capital letters for the output variables
  #

  NX, NY = 512, 512
  # 0.5 arcsec pixels
  dRA, dDec = -0.3/3600., 0.3/3600.
  # Center on central star of NGC 6210
  RA0, Dec0 = 251.122998321, 23.7998586853
  W = WCS(naxis=2)
  W.wcs.cdelt = [dRA, dDec]
  W.wcs.crpix = [0.5*(1 + NX), 0.5*(1 + NY)]
  W.wcs.crval = [RA0, Dec0]
  W.wcs.ctype = ['RA---TAN', 'DEC--TAN']

  outimage = np.zeros((NY, NX))
  # Create world coord arrays for output image
  II, JJ = np.meshgrid(np.arange(NX), np.arange(NY))
  RA, Dec = W.all_pix2world(II, JJ, 0)

  #
  # Read in the list of slits
  #
  table = Table(rows=tab[1:], names=tab[0])

  for i, row in enumerate(table):
      hdu, = fits.open(f"data/imslit/{row['imslit']}-wcs.fits")
      # image = (hdu.data - row['bias']) / (row['core'] - row['bias'])
      image = hdu.data
      outfilename = f'data/imslit-oiii/imslit-{i:02d}.fits'
      ny, nx = image.shape
      #hdu.header.remove('@EPOCH')
      w = WCS(hdu.header)
      # Create world coord arrays for input image
      ii, jj = np.meshgrid(np.arange(nx), np.arange(ny))
      ra, dec = w.all_pix2world(ii, jj, 0)
      # Do the interpolation
      points = np.array(list(zip(ra.ravel(), dec.ravel())))
      xi = np.array(list(zip(RA.ravel(), Dec.ravel())))
      outimage = griddata(points, image.ravel(), xi, method='nearest').reshape((NY, NX))
      bg = np.nanmedian(outimage[420:, 420:])
      core = np.nanmedian(outimage[230:290, 230:290])
      print(core, bg)
      outimage = (outimage - bg)/(core - bg)
      # Save the output image
      fits.PrimaryHDU(header=W.to_header(), data=outimage).writeto(outfilename, overwrite=True)

#+end_src
**** Combining into median image and divide by it
:PROPERTIES:
:ID:       E0D99541-C96F-4927-8809-7912F10CB724
:END:
#+BEGIN_SRC python :eval no :tangle ../scripts/medianize_images.py
  import sys
  import os
  import glob
  import numpy as np
  from astropy.io import fits

  try:
      datapath = sys.argv[1]
      fnlist = glob.glob(f"{datapath}/imslit-??.fits")
  except:
      sys.exit(f"Usage: {sys.argv[0]} DATAPATH")

  imlist = []
  for fitsname in fnlist:
      hdu, = fits.open(fitsname)
      imlist.append(hdu.data)
  imstack = np.dstack(imlist)
  median = np.median(imstack, axis=-1)
  fits.PrimaryHDU(header=hdu.header,
                  data=median).writeto(f'{datapath}/imslit-median.fits', overwrite=True)

  ratcombo = np.zeros_like(median)
  combo = np.zeros_like(median)
  for im, fn in zip(imlist, fnlist):
      combo = combo + im
      head, tail = os.path.split(fn)
      outname = os.path.join(head, tail.replace('imslit', 'imslit-ratio'))
      ratio = im/median
      ratcombo = ratcombo + ratio
      fits.PrimaryHDU(header=hdu.header,
                      data=ratio).writeto(outname, overwrite=True)
  fits.PrimaryHDU(header=hdu.header,
                  data=ratcombo).writeto(f'{datapath}/imslit-ratcombo.fits',
                                         overwrite=True)
  fits.PrimaryHDU(header=hdu.header,
                  data=combo).writeto(f'{datapath}/imslit-combo.fits',
                                      overwrite=True)

#+END_SRC

**** H\alpha + [N II] positions
:PROPERTIES:
:ID:       BE8A01A9-0999-44B5-8A51-E8E4B37960F9
:END:
+ 30 positions in total
+ ~wa = 1~ wavelength is first axis (fits order) in PV spec
+ ~wa = 2~ wavelength is second axis (fits order) in PV spec
+ ~ij = 1~ slit is vertical in I+S, so ~islit~ is along x-axis
+ ~ij = 2~ slit is horizontal in I+S, so ~islit~ is along y-axis
+ ~s = -1~ means that slit axis in I+S is reversed with respect to PV image
+ *Note*
  - spm0172o_b is clearly at an angle to the image axis (of 0.5 deg)

#+name: pos-ha
| spec          | imslit      |     run |    t | wa | islit | ij |  s |
|---------------+-------------+---------+------+----+-------+----+----|
| obj1003_bcrx  | obj1002_bcr | 1998-06 |   60 |  1 |   390 |  1 |  1 |
| obj1007_bcrx  | obj1006_bcr | 1998-06 |  300 |  1 |   388 |  1 |  1 |
| obj1010_bcrx  | obj1009_bcr | 1998-06 | 1200 |  1 |   388 |  1 |  1 |
| obj1015_bcrx  | obj1012_bcr | 1998-06 | 1200 |  1 | 390.5 |  1 |  1 |
| obj1018_bcrx  | obj1017_bcr | 1998-06 | 1200 |  1 | 390.5 |  1 |  1 |
| spm112_bcrx   | spm110_u    | 2003-06 | 1800 |  1 |   257 |  1 |  1 |
| spm116_bcrx   | spm115_bcr  | 2003-06 | 1800 |  1 |   263 |  1 |  1 |
| spm119_bcrx   | spm118_bcr  | 2003-06 | 1800 |  1 |   265 |  1 |  1 |
| spm122_bcrx   | spm121_bcr  | 2003-06 | 1800 |  1 |   267 |  1 |  1 |
| spm125_bcrx   | spm124_bcr  | 2003-06 | 1800 |  1 | 269.5 |  1 |  1 |
| spm130_bcrx   | spm127_bcr  | 2003-06 | 1800 |  1 | 272.5 |  1 |  1 |
| spm135_bcrx   | spm134_bcr  | 2003-06 | 1800 |  1 | 277.5 |  1 |  1 |
| spm224_bcrx   | spm223_bcr  | 2003-10 | 1800 |  1 | 294.5 |  1 |  1 |
| spm230_bcrx   | spm229_bcr  | 2003-10 | 1800 |  1 | 294.5 |  1 |  1 |
| spm329_bcrx   | spm328_bcr  | 2003-10 | 1800 |  1 |   273 |  1 |  1 |
| spm112-2_bcrx | spm111_cr   | 2011-05 | 1800 |  2 |   531 |  2 |  1 |
| spm018-bcrx   | spm017_b    | 2013-07 | 1800 |  1 |   505 |  2 | -1 |
| spm020-bcrx   | spm019_b    | 2013-07 | 1800 |  1 |   483 |  2 | -1 |
| spm023-bcrx   | spm021_b    | 2013-07 | 1800 |  1 |   496 |  2 | -1 |
| spm0031o_bcrx | spm0030o_b  | 2015-08 |  900 |  2 |   485 |  2 |  1 |
| spm0037o_bcrx | spm0036o_b  | 2015-08 |  900 |  2 |   484 |  2 |  1 |
| spm0043o_bcrx | spm0042o_b  | 2015-08 |  900 |  2 |   481 |  2 |  1 |
| spm0049o_bcrx | spm0048o_b  | 2015-08 |  900 |  2 |   480 |  2 |  1 |
| spm0057o_bcrx | spm0056o_b  | 2015-08 |  900 |  2 |   476 |  2 |  1 |
| spm0110o_bcrx | spm0109o_b  | 2015-08 | 1200 |  2 | 490.5 |  2 |  1 |
| spm0116o_bcrx | spm0115o_b  | 2015-08 | 1800 |  2 | 485.5 |  2 |  1 |
| spm0124o_bcrx | spm0123o_b  | 2015-08 | 1200 |  2 |   478 |  2 |  1 |
| spm0173o_bcrx | spm0172o_b  | 2015-08 |  900 |  2 |   493 |  2 |  1 |
| spm0179o_bcrx | spm0178o_b  | 2015-08 | 1800 |  2 | 489.5 |  2 |  1 |
| spm0186o_bcrx | spm0185o_b  | 2015-08 | 1800 |  2 | 515.5 |  2 |  1 |
**** [O III] positions
+ Now including short exposures as well because some of the long ones are saturated
#+name: pos-oiii
| spec              | imslit       |     run |    t | wa | islit | ij |  s |
|-------------------+--------------+---------+------+----+-------+----+----|
| spm243-244_bcrx   | spm242_bcr   | 2004-06 |  120 |  1 |   275 |  1 |  1 |
| spm252_bcrx       | spm251_bcr   | 2004-06 |  120 |  1 |   280 |  1 |  1 |
| spm257_bcrx       | spm256_bcr   | 2004-06 |  120 |  1 |   285 |  1 |  1 |
| spm244_bcrx       | spm242_bcr   | 2004-06 | 1800 |  1 |   275 |  1 |  1 |
| spm253_bcrx       | spm251_bcr   | 2004-06 | 1800 |  1 |   280 |  1 |  1 |
| spm258_bcrx       | spm256_bcr   | 2004-06 | 1800 |  1 |   285 |  1 |  1 |
| spm294_bcrx_oiii  | spm293_bcr   | 2004-06 | 1800 |  1 |   262 |  1 |  1 |
| spm297_bcrx       | spm296_bcr   | 2004-06 | 1800 |  1 |   265 |  1 |  1 |
| spm114_bcrx_oiii  | spm116-2_bcr | 2011-05 |  600 |  2 |   532 |  2 |  1 |
| spm0033_bcrx_oiii | spm0035o_b   | 2015-08 |  900 |  2 |   485 |  2 |  1 |
| spm0039_bcrx_oiii | spm0041o_b   | 2015-08 |  900 |  2 |   482 |  2 |  1 |
| spm0045o_bcrx     | spm0047o_b   | 2015-08 |  900 |  2 |   479 |  2 |  1 |
| spm0051_bcrx_oiii | spm0053o_b   | 2015-08 |  900 |  2 |   476 |  2 |  1 |
| spm0059_oiii      | spm0061o_b   | 2015-08 |  900 |  1 |   475 |  2 | -1 |
| spm0112_bcrx_oiii | spm0114o_b   | 2015-08 | 1200 |  2 |   486 |  2 |  1 |
| spm0118_bcrx_oiii | spm0120o_b   | 2015-08 | 1800 |  2 | 479.5 |  2 |  1 |
| spm0126_bcrx_oiii | spm0128o_b   | 2015-08 | 1200 |  2 | 476.5 |  2 |  1 |
| spm0175o_bcrx     | spm0177o_b   | 2015-08 |  900 |  2 | 489.5 |  2 |  1 |
| spm0181_bcrx_oiii | spm0183o_b   | 2015-08 | 1800 |  2 |   482 |  2 |  1 |
| spm0188_oiii      | spm0190o_b   | 2015-08 | 1800 |  1 |   512 |  2 | -1 |

**** [S II] exposure
| spec   | imslit |     run |    t | wa | islit | ij |
|--------+--------+---------+------+----+-------+----|
| spm408 | spm407 | 2004-06 | 1800 |  1 |   269 |  1 |
**** Write tables to files for later use

First the H\alpha slits

#+name: save-slit-table
#+begin_src python :results file :return path :colnames no :var INTAB=pos-ha FN="ha-slits.tab"
  from astropy.table import Table
  path = f"../data/{FN}"
  Table(rows=INTAB[1:], names=INTAB[0]).write(path, format="ascii.tab")
#+end_src

#+RESULTS: save-slit-table
[[file:../data/ha-slits.tab]]

Second, the [O III] slits

#+call: save-slit-table(pos-oiii, "oiii-slits.tab")

#+RESULTS:
[[file:../data/oiii-slits.tab]]

** [1/1] Relative photometric calibration of the slits
*** DONE Obtain reference profiles from the median image
CLOSED: [2019-05-31 Fri 13:43]
+ [2/2] Steps
  1. [X] Find position of slit on median image
     - ~islit~ from the [[id:BE8A01A9-0999-44B5-8A51-E8E4B37960F9][H\alpha + {N II} positions]] table gives the pixel position perpendicular to slit (give or take a small tilt)
       - We have now written these to ascii files, such as [[file:~/Dropbox/Teresa-Turtle/data/ha-slits.tab]]
     - We can use the star (Ra, Dec) to find (i0, j0) pixel position for star
     - We then have a reference point on the slit (islit, j0), which is closest approach to the star
       - With small modification for ~ij = 2~ since then ~islit~ is in j-direction
  2. [X] With that info, we should be able to make a version of the ~find_slit_coords()~ function, as in the Owl project ([[id:4D50A4AB-80B1-4872-899F-8637EC758AB3][World coords from slit pixels]])
     - Do we even need the star position?
     - No, since we just get the world coords of all the pixels along the slit
*** Compare the slit profiles with the reference profiles
+ In the Owl project, everything was all lumped together, but I am going to do things in stages
+ We don't know what ~shift~ values to use between the im+slit and the PV image, so we will plot the profile comparisons first
+ And first, we will just do Ha + [N II]
+ We will probably have to do it several times, in order to get the ~shift~ values
+ We can have a first guess by collapsing down the image and PV and looking at the location of maximum

#+begin_src python :tangle ../scripts/compare-slit-profiles.py
  import os
  import sys
  import numpy as np
  import astropy
  from astropy.table import Table, Row, hstack
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.wcs.utils import pixel_to_skycoord
  from astropy import units as u
  from astropy.coordinates import SkyCoord
  import seaborn as sns
  import turtle_utils
  from turtle_utils import (
      slit_profile,
      extract_full_profile_from_pv,
      extract_slit_profile_from_imslit,
      get_orig_folder,
      find_slit_coords,
      subtract_sky_and_trim,
      make_three_plots,
      extract_line_and_regularize,
      make_slit_wcs,
  )

  try:
      choice = int(sys.argv[1])
  except:
      choice = None

  restwavs = {'ha': 6562.79, 'nii': 6583.45, 'nii_s': 6548.05}

  # Position of star
  RA0, Dec0 = 251.122998321, 23.7998586853

  saturation = 6e4


  sns.set_palette('RdPu_d', 3)

  table1 = Table.read('data/ha-slits.tab', format="ascii.tab")
  table2 =  Table.read('data/align-ha.tab', format="ascii.tab")
  # The align-ha table takes precedence if islit has been modified
  table1.remove_column("islit")
  # We already have spec in the ha-slits table
  table2.remove_column("spec") 
  table = hstack([table1, table2], join_type="exact")



  # Photometric reference image
  photom, = fits.open('data/imslit-ha/imslit-median.fits')
  wphot = WCS(photom.header)
  turtle_utils.VERBOSE = 1
  neighbors = [-2, -1, 1, 2]
  for row in table:
      if choice is not None and row["id"] != choice:
          # If we asked for a single spectrum, then skip all others
          continue
      spec_hdu, = fits.open(get_orig_folder(row["run"]) + "/" + row["spec"] + ".fits")
      im_hdu, = fits.open("data/imslit/" + row["imslit"] + "-wcs.fits")
      # Mask out saturated pixels with NaN
      spec_hdu.data[spec_hdu.data > saturation] = np.nan
      # trim the edge or arrays since sometimes the outer pixels contain garbage
      spec_hdu.data = subtract_sky_and_trim(spec_hdu.data, row)
      spec_profile = extract_full_profile_from_pv(
          spec_hdu,
          wavaxis=row["wa"],
          bandwidth=90.0,
          linedict=restwavs)
      imslit_profile = extract_slit_profile_from_imslit(im_hdu.data, row)
      print(row)
      jslit = np.arange(len(spec_profile))
      # jslit0_spec = np.average(jslit, weights=spec_profile)
      # jslit0_imslit = np.average(jslit, weights=imslit_profile)
      # jslit0_spec = np.nanargmax(spec_profile)
      # jslit0_imslit = np.nanargmax(imslit_profile)
      jslit0_spec = row["j0_s"]
      jslit0_imslit = row["j0_i"]
      print(jslit0_spec, jslit0_imslit, 'shift =', row["shift"])
      slit_coords = find_slit_coords(row, im_hdu.header, spec_hdu.header)
      calib_profile = slit_profile(slit_coords['RA'], slit_coords['Dec'],
                                   photom.data, wphot)


      # Look at neighboring slit positions
      nb_calib_profiles = {}
      for nb in neighbors:
          nbrow = Table(row)[0]   # This is the trick to get a copy of the row
          nbrow["islit"] += nb
          nb_slit_coords = find_slit_coords(nbrow, im_hdu.header, spec_hdu.header)
          nb_calib_profiles[nb] = slit_profile(
              nb_slit_coords['RA'], nb_slit_coords['Dec'], photom.data, wphot)


      # Offset in arcsec along the slit
      slit_points = (np.arange(len(spec_profile)) - jslit0_spec)*slit_coords["ds"]
      # Extra correction for optical halos that show up at +/- 40 arcsec
      halo_mask = np.abs(np.abs(slit_points) - 40.0) < 10.0
      halo_correction = np.median(spec_profile[halo_mask])
      spec_profile -= halo_correction

      # Take a window about profile peak to normalize spec_profile
      jslice0 = slice(jslit0_spec-20, jslit0_spec+20)
      # propagate saturated pixels to the calibration profile
      calib_profile_nan = calib_profile.copy()
      calib_profile_nan[~np.isfinite(spec_profile)] = np.nan
      rat0 = np.nansum(spec_profile[jslice0])/np.nansum(calib_profile_nan[jslice0])
      print('Coarse calibration: ratio =', rat0)
      spec_profile /= rat0


      # Make a figure comparing the profiles
      plt_prefix = f"figs/{row.index:03d}-calib"
      ratio = make_three_plots(spec_profile, calib_profile, plt_prefix,
                               slit_points=slit_points,
                               neighbors=nb_calib_profiles, db=row, sdb=slit_coords)

      # Write out the flux-calibrated spectra
      spec_hdu.data -= halo_correction
      spec_hdu.data /= rat0
      save_prefix = f"data/pvextract/{row.index:03d}-{row['spec']}"
      # The default header has minimal changes from the original
      pvheader = fits.Header(spec_hdu.header, copy=True)

      for lineid, wav0 in restwavs.items():
          pvdata, contdata, wavs = extract_line_and_regularize(
              spec_hdu.data, WCS(spec_hdu.header), wav0, row)
          pvdata = pvdata[None, :, :]
          contdata = contdata[None, :, :]

          # Create a fancy WCS object for slit coordinates (and a simple one too)
          wslit, wsimp = make_slit_wcs(row, slit_coords, wavs, jslit0_spec)
          # Set the rest wavelength for this line
          wslit.wcs.restwav = (wav0*u.Angstrom).to(u.m).value
          pvheader.update(wsimp.to_header())
          pvheader.update(wslit.to_header(key='A'))
          pvheader['WEIGHT'] = rat0

          pvfile = f"{save_prefix}-{lineid}.fits"
          fits.PrimaryHDU(header=pvheader,
                          data=pvdata).writeto(pvfile, overwrite=True)
          fits.PrimaryHDU(header=pvheader,
                          data=contdata).writeto(pvfile.replace(".fits",
                                                                "-cont.fits"),
                                                 overwrite=True)
#+end_src

+ [X] How to deal with saturation?
  + Done with NaNs
+ Manual changes to alignment along-slit (j0) and across-slit (islit) 
  + 05 j0_i from 268 \to 273
    + Much better in core
  + 06 j0_i from 272 \to 274 AND islit from 263 \to 262
  + 09 j0_i 264 \to 266 AND islit 269.5 \to 268.5
    + Now almost perfect!
  + 12 j0_i 268 \to 264
    + Still not good
  + 13 j0_i 187 -> 190
  + 16 j0_i 644 \to 544
  + 17 j0_i \to 620 and invert sense of axis AND islit 483 \to 481.5
  + 18 j0_i 512 \to 492 (enormous shift) islit 496 \to 500
    + Still not great
  + 19, 20, 21 good near peak - bad in faint parts
  + 22 j0_i 446 \to 447
    + good near peak - bad in faint parts
  + 23 j0_i 448 \to 450 AND islit 476 \to 474
    + Pretty good on left side, but not on right
  + 24 good as is
  + 26 j0_i 544 \to 543 AND islit 478 \to 476
  + 27 j0_i 546 \to 536 AND islit 493 \to 492
    + Another nearly perfect one!


#+name: align-ha
| id | spec          | islit | j0_s |  j0_i | shift |
|----+---------------+-------+------+-------+-------|
| 00 | obj1003_bcrx  |   390 |  336 |   252 |    84 |
| 01 | obj1007_bcrx  |   388 |  325 |   243 |    82 |
| 02 | obj1010_bcrx  |   388 |  327 |   243 |    84 |
| 03 | obj1015_bcrx  | 390.5 |  335 |   254 |    81 |
| 04 | obj1018_bcrx  | 390.5 |  336 |   252 |    84 |
| 05 | spm112_bcrx   |   257 |  316 | 272.5 |  43.5 |
| 06 | spm116_bcrx   |   262 |  318 |   274 |    44 |
| 07 | spm119_bcrx   |   265 |  317 |   271 |    46 |
| 08 | spm122_bcrx   |   266 |  321 | 274.5 |  46.5 |
| 09 | spm125_bcrx   | 268.5 |  314 |   266 |    48 |
| 10 | spm130_bcrx   | 272.5 |  325 |   271 |    54 |
| 11 | spm135_bcrx   | 277.5 |  313 |   260 |    53 |
| 12 | spm224_bcrx   | 294.5 |  329 |   264 |    65 |
| 13 | spm230_bcrx   | 294.5 |  250 |   190 |    60 |
| 14 | spm329_bcrx   |   273 |  321 |   264 |    57 |
| 15 | spm112-2_bcrx |   531 |  509 |   589 |   -80 |
| 16 | spm018-bcrx   |   505 |  508 |   602 |   -94 |
| 17 | spm020-bcrx   | 481.5 |  529 |   622 |   -93 |
| 18 | spm023-bcrx   |   500 |  533 |   640 |  -107 |
| 19 | spm0031o_bcrx |   485 |  331 |   451 |  -120 |
| 20 | spm0037o_bcrx |   484 |  325 |   443 |  -118 |
| 21 | spm0043o_bcrx |   481 |  324 |   446 |  -122 |
| 22 | spm0049o_bcrx |   480 |  324 |   448 |  -124 |
| 23 | spm0057o_bcrx |   474 |  330 |   450 |  -120 |
| 24 | spm0110o_bcrx | 490.5 |  414 |   537 |  -123 |
| 25 | spm0116o_bcrx | 485.5 |  425 |   541 |  -116 |
| 26 | spm0124o_bcrx |   476 |  419 |   543 |  -124 |
| 27 | spm0173o_bcrx |   492 |  412 |   536 |  -124 |
| 28 | spm0179o_bcrx | 489.5 |  410 |   527 |  -117 |
| 29 | spm0186o_bcrx | 515.5 |  398 |   523 |  -125 |
#+TBLFM: $6=$4 - $5

#+call: save-slit-table(align-ha, "align-ha.tab")

#+RESULTS:
[[file:../data/align-ha.tab]]

**** TODO Refinements to the flux calibrations
+ [X] Faint slits: take into account that continuum bandwidth is 90\AA whereas I+S range is only 40\AA
  + This made no discernible difference
+ [X] Bright slits: take into account saturated pixels
  + Can spot them by looking at "Scale parameters" window in DS9
    + Peak in the pixel distribution around the saturation value
  + Saturated exposures
    |    |             |   Sat |  j1 |  j2 |
    |----+-------------+-------+-----+-----|
    | 05 | spm112_bcrx | 63000 | 309 | 322 |
    | 06 | spm116_bcrx | 63000 | 311 | 321 |
    | 08 | spm122_bcrx | 63000 | 317 | 325 |
    | 12 | spm224_bcrx | 63000 | 320 | 338 |
    | 13 | spm230_bcrx | 63000 | 240 | 258 |
    | 14 | spm329_bcrx | 63000 | 313 | 330 |
    + All are from 2003 with 1800 s exposures
  + Saturated [O III] exposures
    + spm244, spm253
+ [ ] Try to deal better with the halo rings  






*** Do the same for [O III]
#+begin_src python :tangle ../scripts/compare-slit-profiles-oiii.py
  import os
  import sys
  import numpy as np
  import astropy
  from astropy.table import Table, Row, hstack
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.wcs.utils import pixel_to_skycoord
  from astropy import units as u
  from astropy.coordinates import SkyCoord
  import seaborn as sns
  import turtle_utils
  from turtle_utils import (
      slit_profile,
      extract_full_profile_from_pv,
      extract_slit_profile_from_imslit,
      get_orig_folder,
      find_slit_coords,
      subtract_sky_and_trim,
      make_three_plots,
      extract_line_and_regularize,
      make_slit_wcs,
  )

  try:
      choice = int(sys.argv[1])
  except:
      choice = None

  restwavs = {}

  # Position of star
  RA0, Dec0 = 251.122998321, 23.7998586853

  saturation = 6e4


  sns.set_palette('RdPu_d', 3)

  table1 = Table.read('data/oiii-slits.tab', format="ascii.tab")
  table2 =  Table.read('data/align-oiii.tab', format="ascii.tab")
  # The align-ha table takes precedence if islit has been modified
  table1.remove_column("islit")
  # We already have spec in the ha-slits table
  table2.remove_column("spec") 
  table = hstack([table1, table2], join_type="exact")



  # Photometric reference image
  photom, = fits.open('data/imslit-oiii/imslit-median.fits')
  wphot = WCS(photom.header)
  turtle_utils.VERBOSE = 1
  neighbors = [-2, -1, 1, 2]
  for row in table:
      if choice is not None and row["id"] != choice:
          # If we asked for a single spectrum, then skip all others
          continue
      spec_hdu, = fits.open(get_orig_folder(row["run"]) + "/" + row["spec"] + ".fits")
      im_hdu, = fits.open("data/imslit/" + row["imslit"] + "-wcs.fits")
      # Mask out saturated pixels with NaN
      spec_hdu.data[spec_hdu.data > saturation] = np.nan
      # trim the edge or arrays since sometimes the outer pixels contain garbage
      spec_hdu.data = subtract_sky_and_trim(spec_hdu.data, row)
      spec_profile = extract_full_profile_from_pv(
          spec_hdu,
          wavaxis=row["wa"],
          bandwidth=None,
          linedict=restwavs)
      imslit_profile = extract_slit_profile_from_imslit(im_hdu.data, row)
      print(row)
      jslit = np.arange(len(spec_profile))
      # jslit0_spec = np.average(jslit, weights=spec_profile)
      # jslit0_imslit = np.average(jslit, weights=imslit_profile)
      # 
      # 
      if row["j0_s"] >= 0:
          jslit0_spec = row["j0_s"]
          jslit0_imslit = row["j0_i"]
      else:
          # First time around, slit alignment with image is not yet determined
          # So just look for maxima in profiles as a first guess
          jslit0_spec = np.nanargmax(spec_profile)
          jslit0_imslit = np.nanargmax(imslit_profile)
          row["shift"] = jslit0_spec - jslit0_imslit
      print(jslit0_spec, jslit0_imslit, 'shift =', row["shift"])
      slit_coords = find_slit_coords(row, im_hdu.header, spec_hdu.header)
      calib_profile = slit_profile(slit_coords['RA'], slit_coords['Dec'],
                                   photom.data, wphot)


      # Look at neighboring slit positions
      nb_calib_profiles = {}
      for nb in neighbors:
          nbrow = Table(row)[0]   # This is the trick to get a copy of the row
          nbrow["islit"] += nb
          nb_slit_coords = find_slit_coords(nbrow, im_hdu.header, spec_hdu.header)
          nb_calib_profiles[nb] = slit_profile(
              nb_slit_coords['RA'], nb_slit_coords['Dec'], photom.data, wphot)


      # Offset in arcsec along the slit
      slit_points = (np.arange(len(spec_profile)) - jslit0_spec)*slit_coords["ds"]
      # Extra correction for bg from pixels > 60 arcsec from peak
      bg_mask = np.abs(np.abs(slit_points) - 60.0) < 10.0
      if np.any(bg_mask):
          bg_correction = np.mean(spec_profile[bg_mask])
      else:
          # If the slit is not long enough, just take the pixels near the ends
          bg_correction = (spec_profile[:5].mean() + spec_profile[-5:].mean())/2.0
      spec_profile -= bg_correction

      # Take a window about profile peak to normalize spec_profile
      jslice0 = slice(jslit0_spec-10, jslit0_spec+10)
      # propagate saturated pixels to the calibration profile
      calib_profile_nan = calib_profile.copy()
      calib_profile_nan[~np.isfinite(spec_profile)] = np.nan
      rat0 = np.nansum(spec_profile[jslice0])/np.nansum(calib_profile_nan[jslice0])
      print('Coarse calibration: ratio =', rat0)
      spec_profile /= rat0


      # Make a figure comparing the profiles
      plt_prefix = f"figs/{row.index:03d}-calib-oiii"
      ratio = make_three_plots(spec_profile, calib_profile, plt_prefix,
                               slit_points=slit_points,
                               neighbors=nb_calib_profiles,
                               db=row, sdb=slit_coords, linelabel="[O III]")

      # Write out the flux-calibrated spectra
      spec_hdu.data -= bg_correction
      spec_hdu.data /= rat0
      save_prefix = f"data/pvextract-oiii/{row.index:03d}-{row['spec']}"
      # The default header has minimal changes from the original
      pvheader = fits.Header(spec_hdu.header, copy=True)

      for lineid, wav0 in restwavs.items():
          pvdata, contdata, wavs = extract_line_and_regularize(
              spec_hdu.data, WCS(spec_hdu.header), wav0, row,
              dw=4.0, dwbg_in=3.0, dwbg_out=4.0)
          pvdata = pvdata[None, :, :]
          contdata = contdata[None, :, :]

          # Create a fancy WCS object for slit coordinates (and a simple one too)
          wslit, wsimp = make_slit_wcs(row, slit_coords, wavs, jslit0_spec)
          # Set the rest wavelength for this line
          wslit.wcs.restwav = (wav0*u.Angstrom).to(u.m).value
          pvheader.update(wsimp.to_header())
          pvheader.update(wslit.to_header(key='A'))
          pvheader['WEIGHT'] = rat0

          pvfile = f"{save_prefix}-{lineid}.fits"
          fits.PrimaryHDU(header=pvheader,
                          data=pvdata).writeto(pvfile, overwrite=True)
          fits.PrimaryHDU(header=pvheader,
                          data=contdata).writeto(pvfile.replace(".fits",
                                                                "-cont.fits"),
                                                 overwrite=True)
#+end_src

#+RESULTS:

First run through, try to determine j0_s, j0_i, and shift automatically

#+name: align-oiii
| id | spec              | islit | j0_s | j0_i | shift |
|----+-------------------+-------+------+------+-------|
| 00 | spm243-244_bcrx   |   275 |  368 |  316 |    52 |
| 01 | spm252_bcrx       |   280 |  363 |  308 |    55 |
| 02 | spm257_bcrx       |   285 |  329 |  271 |    58 |
| 03 | spm244_bcrx       |   275 |  355 |  304 |    51 |
| 04 | spm253_bcrx       |   280 |  360 |  304 |    56 |
| 05 | spm258_bcrx       |   285 |  330 |  271 |    59 |
| 06 | spm294_bcrx_oiii  |   262 |  133 |  238 |  -105 |
| 07 | spm297_bcrx       |   265 |  292 |  244 |    48 |
| 08 | spm114_bcrx_oiii  |   533 |   81 |  600 |  -519 |
| 09 | spm0033_bcrx_oiii | 485.5 |  200 |  444 |  -244 |
| 10 | spm0039_bcrx_oiii |   481 |  197 |  446 |  -249 |
| 11 | spm0045o_bcrx     |   479 |  323 |  447 |  -124 |
| 12 | spm0051_bcrx_oiii |   476 |  196 |  446 |  -250 |
| 13 | spm0059_oiii      |   475 |  168 |  418 |  -250 |
| 14 | spm0112_bcrx_oiii |   486 |  212 |  532 |  -320 |
| 15 | spm0118_bcrx_oiii |   482 |  221 |  548 |  -327 |
| 16 | spm0126_bcrx_oiii | 476.5 |  218 |  541 |  -323 |
| 17 | spm0175o_bcrx     | 489.5 |  410 |  529 |  -119 |
| 18 | spm0181_bcrx_oiii |   480 |  215 |  536 |  -321 |
| 19 | spm0188_oiii      |   508 |  176 |  502 |  -326 |
#+TBLFM: $6=$4 - $5

#+call: save-slit-table(align-oiii, "align-oiii.tab")

#+RESULTS:
[[file:../data/align-oiii.tab]]

+ 00 - j0_i 308 \to 318 and islit 275 \to 273
** Test the heliocentric correction machinery
+ This is completely re-implemented using astropy.coordinates instead of pyslalib.slalib
+ These are largely similar to Teresa's values, but there are differences of up to 0.5 km/s
+ Although I managed to get the old method working as well
  + In the table, ~Helio~ is the astropy result while ~Helio2~ is the slalib result
  + Apart from the opposite sign convention, there are small differences.  Teresa's values seem more similar to the slalib ones (usually within 0.1 km/s)
+ *Conclusion* stick with slalib for now

#+BEGIN_SRC python :return outtab
  import sys
  import os
  import glob
  from astropy.io import fits
  import astropy.coordinates as coord
  from astropy.wcs import WCS
  from astropy.time import Time
  import astropy.units as u
  sys.path.append('/Users/will/Dropbox/OrionWest')
  from helio_utils import helio_topo_from_header

  outtab = [['File', 'Date', 'JD', 'ST', 'RA', 'Dec', 'Helio', 'Helio2'], None]
  speclist = glob.glob('../data/pvextract/0*-ha.fits')
  spm = coord.EarthLocation.of_site("spm")
  for fn in sorted(speclist):
      hdr = fits.open(fn)[0].header
      w = WCS(hdr, key="A")
      wav, c = w.pixel_to_world(1, 1, 1)
      time = Time(w.wcs.dateobs)
      heliocorr = c.radial_velocity_correction(
          'barycentric', obstime=time, location=spm)
      heliocorr2 = helio_topo_from_header(hdr, usewcs='A')
      id_, _ = os.path.splitext(os.path.basename(fn))
      outtab.append([id_, time.iso.split()[0],
                     time.mjd,
                     hdr.get('ST'), hdr.get('RA'), hdr.get('DEC'),
                     '{:.2f}'.format(heliocorr.to(u.km/u.s).value),
                     '{:.2f}'.format(heliocorr2),
      ])
#+END_SRC

#+RESULTS:
| File                 |       Date |      JD |          ST |         RA |        Dec |  Helio | Helio2 |
|----------------------+------------+---------+-------------+------------+------------+--------+--------|
| 000-obj1003_bcrx-ha  | 1998-06-28 | 50992.0 |        None |   16:44:27 |  +23:49:18 | -10.23 |  10.96 |
| 001-obj1007_bcrx-ha  | 1998-06-28 | 50992.0 |        None |   16:44:27 |  +23:49:30 | -10.23 |  10.96 |
| 002-obj1010_bcrx-ha  | 1998-06-28 | 50992.0 |        None |   16:44:26 |  +23:49:41 | -10.23 |  10.96 |
| 003-obj1015_bcrx-ha  | 1998-06-28 | 50992.0 |        None |   16:44:26 |  +23:49:07 | -10.23 |  10.96 |
| 004-obj1018_bcrx-ha  | 1998-06-28 | 50992.0 |        None |   16:44:25 |  +23:49:00 | -10.23 |  10.96 |
| 005-spm112_bcrx-ha   | 2003-06-05 | 52795.0 |    12:52:39 | 16:44:33.1 |  +23:48:04 |  -2.70 |   2.72 |
| 006-spm116_bcrx-ha   | 2003-06-05 | 52795.0 |    13:39:05 | 16:44:34.6 |  +23:47:59 |  -2.70 |   2.77 |
| 007-spm119_bcrx-ha   | 2003-06-05 | 52795.0 |    14:19:50 | 16:44:33.2 |  +23:47:55 |  -2.70 |   2.81 |
| 008-spm122_bcrx-ha   | 2003-06-05 | 52795.0 |    15:00:09 | 16:44:33.4 |  +23:47:52 |  -2.70 |   2.87 |
| 009-spm125_bcrx-ha   | 2003-06-05 | 52795.0 |    15:40:59 | 16:44:33.6 |  +23:47:51 |  -2.70 |   2.93 |
| 010-spm130_bcrx-ha   | 2003-06-05 | 52795.0 |    16:58:37 | 16:44:37.3 |  +23:47:53 |  -2.70 |   3.06 |
| 011-spm135_bcrx-ha   | 2003-06-05 | 52795.0 |    17:33:41 | 16:44:39.6 |  +23:47:56 |  -2.70 |   3.11 |
| 012-spm224_bcrx-ha   | 2003-10-16 | 52928.0 |    20:14:28 | 16:44:35.5 |  +23:48:04 | -14.08 |  14.26 |
| 013-spm230_bcrx-ha   | 2003-10-16 | 52928.0 |    21:04:08 | 16:44:33.0 |  +23:48:17 | -14.08 |  14.30 |
| 014-spm329_bcrx-ha   | 2003-10-17 | 52929.0 |    21:03:29 | 16:44:41.7 |  +23:48:16 | -13.79 |  14.00 |
| 015-spm112-2_bcrx-ha | 2011-05-21 | 55702.0 |    13:13:44 | 16:44:58.3 |  +23:46:31 |   2.51 |  -2.50 |
| 016-spm018-bcrx-ha   | 2013-07-06 | 56479.0 |    16:47:45 | 16:45:07.1 | 23:46:20.0 | -12.53 |  12.90 |
| 017-spm020-bcrx-ha   | 2013-07-06 | 56479.0 |    17:26:00 | 16:45:05.8 | 23:46:20.0 | -12.53 |  12.96 |
| 018-spm023-bcrx-ha   | 2013-07-06 | 56479.0 |    18:04:36 | 16:45:05.9 | 23:46:21.0 | -12.53 |  13.02 |
| 019-spm0031o_bcrx-ha | 2015-08-18 | 57252.0 | 18:02:23.50 | 16:45:10.6 | 23:46:44.0 | -20.04 |  20.40 |
| 020-spm0037o_bcrx-ha | 2015-08-18 | 57252.0 | 18:54:04.96 | 16:45:09.9 | 23:46:45.0 | -20.04 |  20.47 |
| 021-spm0043o_bcrx-ha | 2015-08-18 | 57252.0 | 19:35:53.81 | 16:45:08.9 | 23:46:49.0 | -20.04 |  20.53 |
| 022-spm0049o_bcrx-ha | 2015-08-18 | 57252.0 | 20:13:41.00 | 16:45:08.1 | 23:46:54.0 | -20.04 |  20.57 |
| 023-spm0057o_bcrx-ha | 2015-08-18 | 57252.0 | 20:59:43.55 | 16:45:08.1 | 23:46:59.0 | -20.04 |  20.61 |
| 024-spm0110o_bcrx-ha | 2015-08-19 | 57253.0 | 17:48:56.19 | 16:45:08.7 | 23:46:43.0 | -20.10 |  20.44 |
| 025-spm0116o_bcrx-ha | 2015-08-19 | 57253.0 | 18:47:13.74 | 16:45:08.6 | 23:46:44.0 | -20.10 |  20.52 |
| 026-spm0124o_bcrx-ha | 2015-08-19 | 57253.0 | 20:19:25.85 | 16:45:05.1 | 23:46:52.0 | -20.10 |  20.63 |
| 027-spm0173o_bcrx-ha | 2015-08-20 | 57254.0 | 17:28:59.83 | 16:45:07.3 | 23:46:42.0 | -20.16 |  20.46 |
| 028-spm0179o_bcrx-ha | 2015-08-20 | 57254.0 | 18:15:15.41 | 16:45:06.5 | 23:46:41.0 | -20.16 |  20.53 |
| 029-spm0186o_bcrx-ha | 2015-08-20 | 57254.0 | 19:36:02.64 | 16:45:05.7 | 23:46:47.0 | -20.16 |  20.64 |
** Write PV spectra with velocities and slit offsets
+ This is based on [[id:510C5A10-37E2-4C7B-9BB7-D63D01022A2D][Write PV spectra with WCS in arcsec relative to star]] from the Owl project
+ But it is more complicated since we have different PAs for the slits
  1. Find separation from star of all points
  2. Take minimum of these as reference point
  3. Slit axis is then separation from reference point
  4. Also record slit PA and slit offset (separation of reference point from star) and offset PA (perp to slit PA)
+ We want the slit axis to increase in direction ...
  + to N for nearly vertical slits
  + to E for nearly horizontal slits

#+BEGIN_SRC python :tangle ../scripts/turtle-pv-relative.py
  import glob
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.wcs.utils import pixel_to_skycoord, skycoord_to_pixel
  import astropy.units as u
  from astropy.coordinates import SkyCoord
  sys.path.append('/Users/will/Dropbox/OrionWest')
  from helio_utils import waves2vels

  # Center on central star of NGC 6210
  RA0, Dec0 = 251.122998321, 23.7998586853
  c0 = SkyCoord(RA0, Dec0, unit="deg")

  wav0_dict = {
      'oiii': 5006.84,
      'ha': 6562.79,
      'nii': 6583.45,
      'nii_s': 6548.05,
  }
  try:
      lineid = sys.argv[1]
  except:
      sys.exit(f"Usage: {sys.argv[0]} {{{'|'.join(wav0_dict)}}}")

  datadir = "pvextract-oiii" if lineid == "oiii" else "pvextract"

  speclist = glob.glob(f'data/{datadir}/*-{lineid}.fits')
  # Rest wavelength in meters
  wav0 = 1e-10*wav0_dict[lineid]


  for fn in speclist:
      print('Processing', fn)
      spechdu, = fits.open(fn)
      wspec = WCS(spechdu.header, key='A')

      # Eliminate degenerate 3rd dimension from data array and trim off bad bits
      spec2d = spechdu.data[0]

      # Convert to heliocentric velocity
      [[wav1, _, _], [wav2, _, _]] = wspec.all_pix2world([[0, 0, 0], [1, 0, 0]], 0)
      [v1, v2] = waves2vels(np.array([wav1, wav2]), wav0, spechdu.header, usewcs="A")


      # sequence of pixels along the slit spatial axis
      ipixels = np.arange(wspec.array_shape[1])
      # sky coordinate that corresponds to each pixel
      coords = pixel_to_skycoord(ipixels, 0, wcs=wspec)
      # separation of each pixel from star
      radii = c0.separation(coords).to(u.arcsec).value
      # reference pixel has minimum separation from star
      iref = radii.argmin()
      cref = coords[iref]
      # slit offset is minimum of radii
      offset = radii.min()
      # but sign depends on PA
      pa_offset = c0.position_angle(cref)
      if np.sin(pa_offset) < 0.0:
          offset *= -1.0

      # separation from reference pixel gives coordinate along slit
      s = cref.separation(coords).to(u.arcsec).value
      # inter-pixel separation
      ds = np.abs(np.diff(s)).mean()
      # PA of slit
      pa = cref.position_angle(coords[-1])
      if np.cos(pa) < 0.0:
          # Make sure positive offset is to N
          ds *= -1.0
          # And flip slit PA to compensate
          pa += np.pi*u.rad

      wnew = WCS(naxis=2)
      wnew.wcs.ctype = ['VHEL', 'LINEAR']
      wnew.wcs.crpix = [1, iref+1]
      wnew.wcs.cunit = ['km/s', 'arcsec']
      wnew.wcs.crval = [v1.to('km/s').value, 0.0]
      wnew.wcs.cdelt = [(v2 - v1).to('km/s').value, ds]

      newsuffix = f"-PA{int(pa.to(u.deg).value)%360:03d}-sep{int(offset):+04d}"    
      newhdr = wnew.to_header()
      newhdr["PA"] = pa.to(u.deg).value, "Position angle of slit, degrees"
      newhdr["OFFSET"] = offset, "Perpendicular offset of slit from star, arcsec"
      new_fn = fn.replace(f'data/{datadir}/', 'data/PVoffset/')
      new_fn = new_fn.replace('.fits', newsuffix + '.fits')
      fits.PrimaryHDU(data=spec2d, header=newhdr).writeto(new_fn, overwrite=True)

#+END_SRC


** Finally make the spectral maps
+ Again, initially copied from Owl version
  + [[id:B7F104C4-6CAA-4462-81A9-FBCB4C86BDE2][Construct spectral maps @ teresa-owl.org]]
+ Output image is same as in [[id:4FA9561B-6694-4D6F-98DE-320EB1FEAB0E][Re-gridding images]] above
  + 512x512 with 0.3 arcsec pixels
+ To deal with saturated pixels:
  + Make an array of per-pixel weights
  + Set profile and weight to zeros wherever there are NaNs


#+BEGIN_SRC python :tangle ../scripts/turtle-spectral-map.py
  import glob
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.wcs.utils import pixel_to_skycoord, skycoord_to_pixel
  import astropy.units as u
  sys.path.append('/Users/will/Dropbox/OrionWest')
  from helio_utils import helio_topo_from_header, vels2waves


  try:
      line_id = sys.argv[1]
  except IndexError:
      print('Usage: {} LINE_ID [VRANGE [OUTPUT_FOLDER]]'.format(sys.argv[0]))

  try:
      vrange = sys.argv[2]
  except IndexError:
      vrange = None

  try:
      outdir = sys.argv[3]
  except IndexError:
      outdir = "maps"

  print("(line_id, vrange, outdir) = ", line_id, vrange, outdir)

  def waves2pixels(waves, w):
      n = len(waves)
      pixels, _, _ = w.all_world2pix(waves, [RA0]*n, [Dec0]*n, 0)
      return pixels.astype(int)

  datadir_dict = {
      # special cases
      "oiii": "data/pvextract-oiii",
  }
  datadir = datadir_dict.get(line_id, "data/pvextract")

  # First set up WCS for the output image
  #
  NX, NY = 512, 512
  pixel_scale = 0.3               # arcsec
  dRA, dDec = -pixel_scale/3600., pixel_scale/3600.
  # Center on central star of NGC 6210
  RA0, Dec0 = 251.122998321, 23.7998586853
  w = WCS(naxis=2)
  w.wcs.cdelt = [dRA, dDec]
  w.wcs.crpix = [0.5*(1 + NX), 0.5*(1 + NY)]
  w.wcs.crval = [RA0, Dec0]
  w.wcs.ctype = ['RA---TAN', 'DEC--TAN']
  w.wcs.cunit = ['deg', 'deg']

  # Arrays to hold the output image
  outimage = np.zeros((NY, NX))
  outweights = np.zeros((NY, NX))

  # Use a slightly wider slit than is strictly accurate 
  slit_width = 1.0                
  slit_pix_width = slit_width/pixel_scale

  speclist = glob.glob(f'{datadir}/*-{line_id}.fits')

  # Window widths for line and BG
  dwline = 7.0*u.Angstrom

  for fn in speclist:
      print('Processing', fn)
      spechdu, = fits.open(fn)
      wspec = WCS(spechdu.header, key='A')

      # Trim to good portion of the slit
      goodslice = slice(None, None)

      # Find per-slit weight
      slit_weight = spechdu.header['WEIGHT']

      # Find sign of delta wavelength
      dwav = wspec.wcs.get_cdelt()[0]*wspec.wcs.get_pc()[0, 0]
      sgn = int(dwav/abs(dwav))         # Need to take slices backwards if this is negative

      # Eliminate degenerate 3rd dimension from data array and trim off bad bits
      spec2d = spechdu.data[0]

      # Rest wavelength from FITS header is in meters
      wavrest = wspec.wcs.restwav*u.m

      # Find wavelength limits for line extraction window
      if vrange is None:
          # Original case: use a window of wavelength full width dwline
          waves =  wavrest + np.array([-0.5, 0.5])*dwline
      else:
          # Extract velocity limits from the vrange command line argument
          # vrange should be of a form like '-100+100' or '+020+030'
          v1, v2 = float(vrange[:4]), float(vrange[-4:])
          print('Velocity window:', v1, 'to', v2)
          waves = vels2waves([v1, v2], wavrest,  spechdu.header, usewcs="A")
      print('Wavelength window: {:.2f} to {:.2f}'.format(*waves.to(u.Angstrom)))

      # Find pixel indices for line extraction window
      i1, i2 = waves2pixels(waves, wspec)
      print('Pixel window:', i1, 'to', i2, 'in direction', sgn)

      # Extract profile for this wavelength or velocity window
      profile = spec2d[:, i1:i2:sgn].sum(axis=-1)

      # Find celestial coordinates for each pixel along the slit
      NS = len(profile)
      slit_coords = pixel_to_skycoord(range(NS), [0]*NS, wspec, 0)

      # Trim off bad parts of slit
      profile = profile[goodslice]
      slit_coords = slit_coords[goodslice]

      # Deal with NaNs in profile:
      # - Make an array of per-pixel weights
      wp = np.ones_like(profile)*slit_weight
      # - Set profile and weight to zeros wherever there are NaNs
      badmask = ~np.isfinite(profile)
      profile[badmask] = 0.0
      wp[badmask] = 0.0

      # Convert to pixel coordinates in output image
      xp, yp = skycoord_to_pixel(slit_coords, w, 0)

      for x, y, bright, wt in zip(xp, yp, profile, wp):
          # Find output pixels corresponding to corners of slit pixel
          # (approximate as square)
          i1 = int(0.5 + x - slit_pix_width/2)
          i2 = int(0.5 + x + slit_pix_width/2)
          j1 = int(0.5 + y - slit_pix_width/2)
          j2 = int(0.5 + y + slit_pix_width/2)
          # Make sure we don't go outside the output grid
          i1, i2 = max(0, i1), max(0, i2)
          i1, i2 = min(NX, i1), min(NX, i2)
          j1, j2 = max(0, j1), max(0, j2)
          j1, j2 = min(NY, j1), min(NY, j2)
          # Fill in the square
          outimage[j1:j2, i1:i2] += bright*wt
          outweights[j1:j2, i1:i2] += wt

  # Save everything as different images in a single fits file:
  # 1. The sum of the raw slits 
  # 2. The weights
  # 3. The slits normalized by the weights
  if vrange is None:
      label = line_id + '-allvels'
  else:
      label = line_id + vrange

  outfile = f'data/{outdir}/turtle-slits-{label}.fits'
  print("Writing to", outfile)
  fits.HDUList([
      fits.PrimaryHDU(),
      fits.ImageHDU(header=w.to_header(), data=outimage, name='slits'),
      fits.ImageHDU(header=w.to_header(), data=outweights, name='weight'),
      fits.ImageHDU(header=w.to_header(), data=outimage/outweights, name='scaled'),
      ]).writeto(outfile, overwrite=True)
#+END_SRC



*** Make the maps
#+BEGIN_SRC sh :tangle ../scripts/make-isovel-maps.sh :eval no
  ranges='+030+040 +020+030 +010+020 +000+010 -010+000 -020-010 -030-020 -040-030 -050-040 -060-050 -070-060 -080-070 -090-080'
  # blueranges='-030-010 -050-030 -070-050'
  # farblueranges='-090-070 -110-090 -130-110'
  # for vrange in $redranges $blueranges $farblueranges; do
  for vrange in $ranges; do
      python scripts/turtle-spectral-map.py ha $vrange
      python scripts/turtle-spectral-map.py nii $vrange
  done
#+END_SRC

Extras to widen the range
#+BEGIN_SRC sh :tangle ../scripts/make-isovel-maps-extras.sh :eval no
  ranges='+040+050 -100-090 -110-100'
  for vrange in $ranges; do
      python scripts/turtle-spectral-map.py ha $vrange
      python scripts/turtle-spectral-map.py nii $vrange
  done
#+END_SRC

And wider channels of 20 km/s
#+BEGIN_SRC sh :tangle ../scripts/make-isovel-maps-20.sh :eval no
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  for vrange in $ranges; do
      python scripts/turtle-spectral-map.py ha $vrange maps20
      python scripts/turtle-spectral-map.py nii $vrange maps20
  done
#+END_SRC


And [O III]
#+BEGIN_SRC sh :tangle ../scripts/make-isovel-maps-oiii-20.sh :eval no
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  # blueranges='-030-010 -050-030 -070-050'
  # farblueranges='-090-070 -110-090 -130-110'
  # for vrange in $redranges $blueranges $farblueranges; do
  for vrange in $ranges; do
      python scripts/turtle-spectral-map.py oiii $vrange maps-oiii-20
  done
#+END_SRC



*** Look at some of the maps
Central velocities in Ha
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-ha-030-020.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-ha-040-030.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-ha-050-040.fits[3]
#+END_SRC

Central velocities in [N II]
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-nii-030-020.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-nii-040-030.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-nii-050-040.fits[3]
#+END_SRC

Near red velocities in Ha
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-ha+000+010.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-ha-010+000.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-ha-020-010.fits[3]
#+END_SRC

Near red velocities in [N II]
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-nii+000+010.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-nii-010+000.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-nii-020-010.fits[3]
#+END_SRC

Blue velocities in Ha
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-ha-070-060.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-ha-080-070.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-ha-090-080.fits[3]
#+END_SRC

Blue velocities in [N II]
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-nii-070-060.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-nii-080-070.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-nii-090-080.fits[3]
#+END_SRC

Red velocities in [N II]
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-nii+030+040.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-nii+020+030.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-nii+010+020.fits[3]
#+END_SRC

Near blue velocities in [N II]
#+BEGIN_SRC sh :dir ../data/maps :results silent
xpaset -p ds9 rgb red
xpaset -p ds9 fits $PWD/turtle-slits-nii-050-040.fits[3]
xpaset -p ds9 rgb green
xpaset -p ds9 fits $PWD/turtle-slits-nii-060-050.fits[3]
xpaset -p ds9 rgb blue
xpaset -p ds9 fits $PWD/turtle-slits-nii-070-060.fits[3]
#+END_SRC


Central velocities in [O III] - 20 km/s channels
#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-020+000.fits[3]
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-040-020.fits[3]
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-060-040.fits[3]
#+END_SRC

Blue velocities in [O III] - 20 km/s channels
#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-080-060.fits[3]
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-100-080.fits[3]
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-120-100.fits[3]
#+END_SRC

Red velocities in [O III] - 20 km/s channels
#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+040+060.fits[3]
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+020+040.fits[3]
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+000+020.fits[3]
#+END_SRC



** Multibinning
#+BEGIN_SRC sh :results verbatim :dir ../data/maps
  mdir=/Users/will/Dropbox/OrionWest
  ranges='+030+040 +020+030 +010+020 +000+010 -010+000 -020-010 -030-020 -040-030 -050-040 -060-050 -070-060 -080-070 -090-080'
  for vrange in $ranges -allvels; do
      python $mdir/multibin-map.py turtle-slits-ha$vrange.fits
      python $mdir/multibin-map.py turtle-slits-nii$vrange.fits
  done
#+END_SRC

#+RESULTS:
#+begin_example
Saving turtle-slits-ha+030+040-bin001.fits
Saving turtle-slits-ha+030+040-bin002.fits
Saving turtle-slits-ha+030+040-bin004.fits
Saving turtle-slits-ha+030+040-bin008.fits
Saving turtle-slits-ha+030+040-bin016.fits
Saving turtle-slits-ha+030+040-bin032.fits
Saving turtle-slits-ha+030+040-bin064.fits
Saving turtle-slits-nii+030+040-bin001.fits
Saving turtle-slits-nii+030+040-bin002.fits
Saving turtle-slits-nii+030+040-bin004.fits
Saving turtle-slits-nii+030+040-bin008.fits
Saving turtle-slits-nii+030+040-bin016.fits
Saving turtle-slits-nii+030+040-bin032.fits
Saving turtle-slits-nii+030+040-bin064.fits
Saving turtle-slits-ha+020+030-bin001.fits
Saving turtle-slits-ha+020+030-bin002.fits
Saving turtle-slits-ha+020+030-bin004.fits
Saving turtle-slits-ha+020+030-bin008.fits
Saving turtle-slits-ha+020+030-bin016.fits
Saving turtle-slits-ha+020+030-bin032.fits
Saving turtle-slits-ha+020+030-bin064.fits
Saving turtle-slits-nii+020+030-bin001.fits
Saving turtle-slits-nii+020+030-bin002.fits
Saving turtle-slits-nii+020+030-bin004.fits
Saving turtle-slits-nii+020+030-bin008.fits
Saving turtle-slits-nii+020+030-bin016.fits
Saving turtle-slits-nii+020+030-bin032.fits
Saving turtle-slits-nii+020+030-bin064.fits
Saving turtle-slits-ha+010+020-bin001.fits
Saving turtle-slits-ha+010+020-bin002.fits
Saving turtle-slits-ha+010+020-bin004.fits
Saving turtle-slits-ha+010+020-bin008.fits
Saving turtle-slits-ha+010+020-bin016.fits
Saving turtle-slits-ha+010+020-bin032.fits
Saving turtle-slits-ha+010+020-bin064.fits
Saving turtle-slits-nii+010+020-bin001.fits
Saving turtle-slits-nii+010+020-bin002.fits
Saving turtle-slits-nii+010+020-bin004.fits
Saving turtle-slits-nii+010+020-bin008.fits
Saving turtle-slits-nii+010+020-bin016.fits
Saving turtle-slits-nii+010+020-bin032.fits
Saving turtle-slits-nii+010+020-bin064.fits
Saving turtle-slits-ha+000+010-bin001.fits
Saving turtle-slits-ha+000+010-bin002.fits
Saving turtle-slits-ha+000+010-bin004.fits
Saving turtle-slits-ha+000+010-bin008.fits
Saving turtle-slits-ha+000+010-bin016.fits
Saving turtle-slits-ha+000+010-bin032.fits
Saving turtle-slits-ha+000+010-bin064.fits
Saving turtle-slits-nii+000+010-bin001.fits
Saving turtle-slits-nii+000+010-bin002.fits
Saving turtle-slits-nii+000+010-bin004.fits
Saving turtle-slits-nii+000+010-bin008.fits
Saving turtle-slits-nii+000+010-bin016.fits
Saving turtle-slits-nii+000+010-bin032.fits
Saving turtle-slits-nii+000+010-bin064.fits
Saving turtle-slits-ha-010+000-bin001.fits
Saving turtle-slits-ha-010+000-bin002.fits
Saving turtle-slits-ha-010+000-bin004.fits
Saving turtle-slits-ha-010+000-bin008.fits
Saving turtle-slits-ha-010+000-bin016.fits
Saving turtle-slits-ha-010+000-bin032.fits
Saving turtle-slits-ha-010+000-bin064.fits
Saving turtle-slits-nii-010+000-bin001.fits
Saving turtle-slits-nii-010+000-bin002.fits
Saving turtle-slits-nii-010+000-bin004.fits
Saving turtle-slits-nii-010+000-bin008.fits
Saving turtle-slits-nii-010+000-bin016.fits
Saving turtle-slits-nii-010+000-bin032.fits
Saving turtle-slits-nii-010+000-bin064.fits
Saving turtle-slits-ha-020-010-bin001.fits
Saving turtle-slits-ha-020-010-bin002.fits
Saving turtle-slits-ha-020-010-bin004.fits
Saving turtle-slits-ha-020-010-bin008.fits
Saving turtle-slits-ha-020-010-bin016.fits
Saving turtle-slits-ha-020-010-bin032.fits
Saving turtle-slits-ha-020-010-bin064.fits
Saving turtle-slits-nii-020-010-bin001.fits
Saving turtle-slits-nii-020-010-bin002.fits
Saving turtle-slits-nii-020-010-bin004.fits
Saving turtle-slits-nii-020-010-bin008.fits
Saving turtle-slits-nii-020-010-bin016.fits
Saving turtle-slits-nii-020-010-bin032.fits
Saving turtle-slits-nii-020-010-bin064.fits
Saving turtle-slits-ha-030-020-bin001.fits
Saving turtle-slits-ha-030-020-bin002.fits
Saving turtle-slits-ha-030-020-bin004.fits
Saving turtle-slits-ha-030-020-bin008.fits
Saving turtle-slits-ha-030-020-bin016.fits
Saving turtle-slits-ha-030-020-bin032.fits
Saving turtle-slits-ha-030-020-bin064.fits
Saving turtle-slits-nii-030-020-bin001.fits
Saving turtle-slits-nii-030-020-bin002.fits
Saving turtle-slits-nii-030-020-bin004.fits
Saving turtle-slits-nii-030-020-bin008.fits
Saving turtle-slits-nii-030-020-bin016.fits
Saving turtle-slits-nii-030-020-bin032.fits
Saving turtle-slits-nii-030-020-bin064.fits
Saving turtle-slits-ha-040-030-bin001.fits
Saving turtle-slits-ha-040-030-bin002.fits
Saving turtle-slits-ha-040-030-bin004.fits
Saving turtle-slits-ha-040-030-bin008.fits
Saving turtle-slits-ha-040-030-bin016.fits
Saving turtle-slits-ha-040-030-bin032.fits
Saving turtle-slits-ha-040-030-bin064.fits
Saving turtle-slits-nii-040-030-bin001.fits
Saving turtle-slits-nii-040-030-bin002.fits
Saving turtle-slits-nii-040-030-bin004.fits
Saving turtle-slits-nii-040-030-bin008.fits
Saving turtle-slits-nii-040-030-bin016.fits
Saving turtle-slits-nii-040-030-bin032.fits
Saving turtle-slits-nii-040-030-bin064.fits
Saving turtle-slits-ha-050-040-bin001.fits
Saving turtle-slits-ha-050-040-bin002.fits
Saving turtle-slits-ha-050-040-bin004.fits
Saving turtle-slits-ha-050-040-bin008.fits
Saving turtle-slits-ha-050-040-bin016.fits
Saving turtle-slits-ha-050-040-bin032.fits
Saving turtle-slits-ha-050-040-bin064.fits
Saving turtle-slits-nii-050-040-bin001.fits
Saving turtle-slits-nii-050-040-bin002.fits
Saving turtle-slits-nii-050-040-bin004.fits
Saving turtle-slits-nii-050-040-bin008.fits
Saving turtle-slits-nii-050-040-bin016.fits
Saving turtle-slits-nii-050-040-bin032.fits
Saving turtle-slits-nii-050-040-bin064.fits
Saving turtle-slits-ha-060-050-bin001.fits
Saving turtle-slits-ha-060-050-bin002.fits
Saving turtle-slits-ha-060-050-bin004.fits
Saving turtle-slits-ha-060-050-bin008.fits
Saving turtle-slits-ha-060-050-bin016.fits
Saving turtle-slits-ha-060-050-bin032.fits
Saving turtle-slits-ha-060-050-bin064.fits
Saving turtle-slits-nii-060-050-bin001.fits
Saving turtle-slits-nii-060-050-bin002.fits
Saving turtle-slits-nii-060-050-bin004.fits
Saving turtle-slits-nii-060-050-bin008.fits
Saving turtle-slits-nii-060-050-bin016.fits
Saving turtle-slits-nii-060-050-bin032.fits
Saving turtle-slits-nii-060-050-bin064.fits
Saving turtle-slits-ha-070-060-bin001.fits
Saving turtle-slits-ha-070-060-bin002.fits
Saving turtle-slits-ha-070-060-bin004.fits
Saving turtle-slits-ha-070-060-bin008.fits
Saving turtle-slits-ha-070-060-bin016.fits
Saving turtle-slits-ha-070-060-bin032.fits
Saving turtle-slits-ha-070-060-bin064.fits
Saving turtle-slits-nii-070-060-bin001.fits
Saving turtle-slits-nii-070-060-bin002.fits
Saving turtle-slits-nii-070-060-bin004.fits
Saving turtle-slits-nii-070-060-bin008.fits
Saving turtle-slits-nii-070-060-bin016.fits
Saving turtle-slits-nii-070-060-bin032.fits
Saving turtle-slits-nii-070-060-bin064.fits
Saving turtle-slits-ha-080-070-bin001.fits
Saving turtle-slits-ha-080-070-bin002.fits
Saving turtle-slits-ha-080-070-bin004.fits
Saving turtle-slits-ha-080-070-bin008.fits
Saving turtle-slits-ha-080-070-bin016.fits
Saving turtle-slits-ha-080-070-bin032.fits
Saving turtle-slits-ha-080-070-bin064.fits
Saving turtle-slits-nii-080-070-bin001.fits
Saving turtle-slits-nii-080-070-bin002.fits
Saving turtle-slits-nii-080-070-bin004.fits
Saving turtle-slits-nii-080-070-bin008.fits
Saving turtle-slits-nii-080-070-bin016.fits
Saving turtle-slits-nii-080-070-bin032.fits
Saving turtle-slits-nii-080-070-bin064.fits
Saving turtle-slits-ha-090-080-bin001.fits
Saving turtle-slits-ha-090-080-bin002.fits
Saving turtle-slits-ha-090-080-bin004.fits
Saving turtle-slits-ha-090-080-bin008.fits
Saving turtle-slits-ha-090-080-bin016.fits
Saving turtle-slits-ha-090-080-bin032.fits
Saving turtle-slits-ha-090-080-bin064.fits
Saving turtle-slits-nii-090-080-bin001.fits
Saving turtle-slits-nii-090-080-bin002.fits
Saving turtle-slits-nii-090-080-bin004.fits
Saving turtle-slits-nii-090-080-bin008.fits
Saving turtle-slits-nii-090-080-bin016.fits
Saving turtle-slits-nii-090-080-bin032.fits
Saving turtle-slits-nii-090-080-bin064.fits
Saving turtle-slits-ha-allvels-bin001.fits
Saving turtle-slits-ha-allvels-bin002.fits
Saving turtle-slits-ha-allvels-bin004.fits
Saving turtle-slits-ha-allvels-bin008.fits
Saving turtle-slits-ha-allvels-bin016.fits
Saving turtle-slits-ha-allvels-bin032.fits
Saving turtle-slits-ha-allvels-bin064.fits
Saving turtle-slits-nii-allvels-bin001.fits
Saving turtle-slits-nii-allvels-bin002.fits
Saving turtle-slits-nii-allvels-bin004.fits
Saving turtle-slits-nii-allvels-bin008.fits
Saving turtle-slits-nii-allvels-bin016.fits
Saving turtle-slits-nii-allvels-bin032.fits
Saving turtle-slits-nii-allvels-bin064.fits
#+end_example

#+BEGIN_SRC sh :results verbatim :dir ../data/maps
  mdir=/Users/will/Dropbox/OrionWest
  ranges='+040+050 -100-090 -110-100'
  for vrange in $ranges; do
      python $mdir/multibin-map.py turtle-slits-ha$vrange.fits
      python $mdir/multibin-map.py turtle-slits-nii$vrange.fits
  done
#+END_SRC

#+RESULTS:
#+begin_example
Saving turtle-slits-ha+040+050-bin001.fits
Saving turtle-slits-ha+040+050-bin002.fits
Saving turtle-slits-ha+040+050-bin004.fits
Saving turtle-slits-ha+040+050-bin008.fits
Saving turtle-slits-ha+040+050-bin016.fits
Saving turtle-slits-ha+040+050-bin032.fits
Saving turtle-slits-ha+040+050-bin064.fits
Saving turtle-slits-nii+040+050-bin001.fits
Saving turtle-slits-nii+040+050-bin002.fits
Saving turtle-slits-nii+040+050-bin004.fits
Saving turtle-slits-nii+040+050-bin008.fits
Saving turtle-slits-nii+040+050-bin016.fits
Saving turtle-slits-nii+040+050-bin032.fits
Saving turtle-slits-nii+040+050-bin064.fits
Saving turtle-slits-ha-100-090-bin001.fits
Saving turtle-slits-ha-100-090-bin002.fits
Saving turtle-slits-ha-100-090-bin004.fits
Saving turtle-slits-ha-100-090-bin008.fits
Saving turtle-slits-ha-100-090-bin016.fits
Saving turtle-slits-ha-100-090-bin032.fits
Saving turtle-slits-ha-100-090-bin064.fits
Saving turtle-slits-nii-100-090-bin001.fits
Saving turtle-slits-nii-100-090-bin002.fits
Saving turtle-slits-nii-100-090-bin004.fits
Saving turtle-slits-nii-100-090-bin008.fits
Saving turtle-slits-nii-100-090-bin016.fits
Saving turtle-slits-nii-100-090-bin032.fits
Saving turtle-slits-nii-100-090-bin064.fits
Saving turtle-slits-ha-110-100-bin001.fits
Saving turtle-slits-ha-110-100-bin002.fits
Saving turtle-slits-ha-110-100-bin004.fits
Saving turtle-slits-ha-110-100-bin008.fits
Saving turtle-slits-ha-110-100-bin016.fits
Saving turtle-slits-ha-110-100-bin032.fits
Saving turtle-slits-ha-110-100-bin064.fits
Saving turtle-slits-nii-110-100-bin001.fits
Saving turtle-slits-nii-110-100-bin002.fits
Saving turtle-slits-nii-110-100-bin004.fits
Saving turtle-slits-nii-110-100-bin008.fits
Saving turtle-slits-nii-110-100-bin016.fits
Saving turtle-slits-nii-110-100-bin032.fits
Saving turtle-slits-nii-110-100-bin064.fits
Saving turtle-slits-ha-allvels-bin001.fits
Saving turtle-slits-ha-allvels-bin002.fits
Saving turtle-slits-ha-allvels-bin004.fits
Saving turtle-slits-ha-allvels-bin008.fits
Saving turtle-slits-ha-allvels-bin016.fits
Saving turtle-slits-ha-allvels-bin032.fits
Saving turtle-slits-ha-allvels-bin064.fits
Saving turtle-slits-nii-allvels-bin001.fits
Saving turtle-slits-nii-allvels-bin002.fits
Saving turtle-slits-nii-allvels-bin004.fits
Saving turtle-slits-nii-allvels-bin008.fits
Saving turtle-slits-nii-allvels-bin016.fits
Saving turtle-slits-nii-allvels-bin032.fits
Saving turtle-slits-nii-allvels-bin064.fits
#+end_example

#+BEGIN_SRC sh :results verbatim :dir ../data/maps20
  mdir=/Users/will/Dropbox/OrionWest
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  for vrange in $ranges; do
      python $mdir/multibin-map.py turtle-slits-ha$vrange.fits
      python $mdir/multibin-map.py turtle-slits-nii$vrange.fits
  done
#+END_SRC

#+RESULTS:
#+begin_example
Saving turtle-slits-ha+040+060-bin001.fits
Saving turtle-slits-ha+040+060-bin002.fits
Saving turtle-slits-ha+040+060-bin004.fits
Saving turtle-slits-ha+040+060-bin008.fits
Saving turtle-slits-ha+040+060-bin016.fits
Saving turtle-slits-ha+040+060-bin032.fits
Saving turtle-slits-ha+040+060-bin064.fits
Saving turtle-slits-nii+040+060-bin001.fits
Saving turtle-slits-nii+040+060-bin002.fits
Saving turtle-slits-nii+040+060-bin004.fits
Saving turtle-slits-nii+040+060-bin008.fits
Saving turtle-slits-nii+040+060-bin016.fits
Saving turtle-slits-nii+040+060-bin032.fits
Saving turtle-slits-nii+040+060-bin064.fits
Saving turtle-slits-ha+020+040-bin001.fits
Saving turtle-slits-ha+020+040-bin002.fits
Saving turtle-slits-ha+020+040-bin004.fits
Saving turtle-slits-ha+020+040-bin008.fits
Saving turtle-slits-ha+020+040-bin016.fits
Saving turtle-slits-ha+020+040-bin032.fits
Saving turtle-slits-ha+020+040-bin064.fits
Saving turtle-slits-nii+020+040-bin001.fits
Saving turtle-slits-nii+020+040-bin002.fits
Saving turtle-slits-nii+020+040-bin004.fits
Saving turtle-slits-nii+020+040-bin008.fits
Saving turtle-slits-nii+020+040-bin016.fits
Saving turtle-slits-nii+020+040-bin032.fits
Saving turtle-slits-nii+020+040-bin064.fits
Saving turtle-slits-ha+000+020-bin001.fits
Saving turtle-slits-ha+000+020-bin002.fits
Saving turtle-slits-ha+000+020-bin004.fits
Saving turtle-slits-ha+000+020-bin008.fits
Saving turtle-slits-ha+000+020-bin016.fits
Saving turtle-slits-ha+000+020-bin032.fits
Saving turtle-slits-ha+000+020-bin064.fits
Saving turtle-slits-nii+000+020-bin001.fits
Saving turtle-slits-nii+000+020-bin002.fits
Saving turtle-slits-nii+000+020-bin004.fits
Saving turtle-slits-nii+000+020-bin008.fits
Saving turtle-slits-nii+000+020-bin016.fits
Saving turtle-slits-nii+000+020-bin032.fits
Saving turtle-slits-nii+000+020-bin064.fits
Saving turtle-slits-ha-020+000-bin001.fits
Saving turtle-slits-ha-020+000-bin002.fits
Saving turtle-slits-ha-020+000-bin004.fits
Saving turtle-slits-ha-020+000-bin008.fits
Saving turtle-slits-ha-020+000-bin016.fits
Saving turtle-slits-ha-020+000-bin032.fits
Saving turtle-slits-ha-020+000-bin064.fits
Saving turtle-slits-nii-020+000-bin001.fits
Saving turtle-slits-nii-020+000-bin002.fits
Saving turtle-slits-nii-020+000-bin004.fits
Saving turtle-slits-nii-020+000-bin008.fits
Saving turtle-slits-nii-020+000-bin016.fits
Saving turtle-slits-nii-020+000-bin032.fits
Saving turtle-slits-nii-020+000-bin064.fits
Saving turtle-slits-ha-040-020-bin001.fits
Saving turtle-slits-ha-040-020-bin002.fits
Saving turtle-slits-ha-040-020-bin004.fits
Saving turtle-slits-ha-040-020-bin008.fits
Saving turtle-slits-ha-040-020-bin016.fits
Saving turtle-slits-ha-040-020-bin032.fits
Saving turtle-slits-ha-040-020-bin064.fits
Saving turtle-slits-nii-040-020-bin001.fits
Saving turtle-slits-nii-040-020-bin002.fits
Saving turtle-slits-nii-040-020-bin004.fits
Saving turtle-slits-nii-040-020-bin008.fits
Saving turtle-slits-nii-040-020-bin016.fits
Saving turtle-slits-nii-040-020-bin032.fits
Saving turtle-slits-nii-040-020-bin064.fits
Saving turtle-slits-ha-060-040-bin001.fits
Saving turtle-slits-ha-060-040-bin002.fits
Saving turtle-slits-ha-060-040-bin004.fits
Saving turtle-slits-ha-060-040-bin008.fits
Saving turtle-slits-ha-060-040-bin016.fits
Saving turtle-slits-ha-060-040-bin032.fits
Saving turtle-slits-ha-060-040-bin064.fits
Saving turtle-slits-nii-060-040-bin001.fits
Saving turtle-slits-nii-060-040-bin002.fits
Saving turtle-slits-nii-060-040-bin004.fits
Saving turtle-slits-nii-060-040-bin008.fits
Saving turtle-slits-nii-060-040-bin016.fits
Saving turtle-slits-nii-060-040-bin032.fits
Saving turtle-slits-nii-060-040-bin064.fits
Saving turtle-slits-ha-080-060-bin001.fits
Saving turtle-slits-ha-080-060-bin002.fits
Saving turtle-slits-ha-080-060-bin004.fits
Saving turtle-slits-ha-080-060-bin008.fits
Saving turtle-slits-ha-080-060-bin016.fits
Saving turtle-slits-ha-080-060-bin032.fits
Saving turtle-slits-ha-080-060-bin064.fits
Saving turtle-slits-nii-080-060-bin001.fits
Saving turtle-slits-nii-080-060-bin002.fits
Saving turtle-slits-nii-080-060-bin004.fits
Saving turtle-slits-nii-080-060-bin008.fits
Saving turtle-slits-nii-080-060-bin016.fits
Saving turtle-slits-nii-080-060-bin032.fits
Saving turtle-slits-nii-080-060-bin064.fits
Saving turtle-slits-ha-100-080-bin001.fits
Saving turtle-slits-ha-100-080-bin002.fits
Saving turtle-slits-ha-100-080-bin004.fits
Saving turtle-slits-ha-100-080-bin008.fits
Saving turtle-slits-ha-100-080-bin016.fits
Saving turtle-slits-ha-100-080-bin032.fits
Saving turtle-slits-ha-100-080-bin064.fits
Saving turtle-slits-nii-100-080-bin001.fits
Saving turtle-slits-nii-100-080-bin002.fits
Saving turtle-slits-nii-100-080-bin004.fits
Saving turtle-slits-nii-100-080-bin008.fits
Saving turtle-slits-nii-100-080-bin016.fits
Saving turtle-slits-nii-100-080-bin032.fits
Saving turtle-slits-nii-100-080-bin064.fits
Saving turtle-slits-ha-120-100-bin001.fits
Saving turtle-slits-ha-120-100-bin002.fits
Saving turtle-slits-ha-120-100-bin004.fits
Saving turtle-slits-ha-120-100-bin008.fits
Saving turtle-slits-ha-120-100-bin016.fits
Saving turtle-slits-ha-120-100-bin032.fits
Saving turtle-slits-ha-120-100-bin064.fits
Saving turtle-slits-nii-120-100-bin001.fits
Saving turtle-slits-nii-120-100-bin002.fits
Saving turtle-slits-nii-120-100-bin004.fits
Saving turtle-slits-nii-120-100-bin008.fits
Saving turtle-slits-nii-120-100-bin016.fits
Saving turtle-slits-nii-120-100-bin032.fits
Saving turtle-slits-nii-120-100-bin064.fits
#+end_example

#+BEGIN_SRC sh :results verbatim :dir ../data/maps-oiii-20
  mdir=/Users/will/Dropbox/OrionWest
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  for vrange in $ranges; do
      python $mdir/multibin-map.py turtle-slits-oiii$vrange.fits
  done
#+END_SRC

#+RESULTS:
#+begin_example
Saving turtle-slits-oiii+040+060-bin001.fits
Saving turtle-slits-oiii+040+060-bin002.fits
Saving turtle-slits-oiii+040+060-bin004.fits
Saving turtle-slits-oiii+040+060-bin008.fits
Saving turtle-slits-oiii+040+060-bin016.fits
Saving turtle-slits-oiii+040+060-bin032.fits
Saving turtle-slits-oiii+040+060-bin064.fits
Saving turtle-slits-oiii+020+040-bin001.fits
Saving turtle-slits-oiii+020+040-bin002.fits
Saving turtle-slits-oiii+020+040-bin004.fits
Saving turtle-slits-oiii+020+040-bin008.fits
Saving turtle-slits-oiii+020+040-bin016.fits
Saving turtle-slits-oiii+020+040-bin032.fits
Saving turtle-slits-oiii+020+040-bin064.fits
Saving turtle-slits-oiii+000+020-bin001.fits
Saving turtle-slits-oiii+000+020-bin002.fits
Saving turtle-slits-oiii+000+020-bin004.fits
Saving turtle-slits-oiii+000+020-bin008.fits
Saving turtle-slits-oiii+000+020-bin016.fits
Saving turtle-slits-oiii+000+020-bin032.fits
Saving turtle-slits-oiii+000+020-bin064.fits
Saving turtle-slits-oiii-020+000-bin001.fits
Saving turtle-slits-oiii-020+000-bin002.fits
Saving turtle-slits-oiii-020+000-bin004.fits
Saving turtle-slits-oiii-020+000-bin008.fits
Saving turtle-slits-oiii-020+000-bin016.fits
Saving turtle-slits-oiii-020+000-bin032.fits
Saving turtle-slits-oiii-020+000-bin064.fits
Saving turtle-slits-oiii-040-020-bin001.fits
Saving turtle-slits-oiii-040-020-bin002.fits
Saving turtle-slits-oiii-040-020-bin004.fits
Saving turtle-slits-oiii-040-020-bin008.fits
Saving turtle-slits-oiii-040-020-bin016.fits
Saving turtle-slits-oiii-040-020-bin032.fits
Saving turtle-slits-oiii-040-020-bin064.fits
Saving turtle-slits-oiii-060-040-bin001.fits
Saving turtle-slits-oiii-060-040-bin002.fits
Saving turtle-slits-oiii-060-040-bin004.fits
Saving turtle-slits-oiii-060-040-bin008.fits
Saving turtle-slits-oiii-060-040-bin016.fits
Saving turtle-slits-oiii-060-040-bin032.fits
Saving turtle-slits-oiii-060-040-bin064.fits
Saving turtle-slits-oiii-080-060-bin001.fits
Saving turtle-slits-oiii-080-060-bin002.fits
Saving turtle-slits-oiii-080-060-bin004.fits
Saving turtle-slits-oiii-080-060-bin008.fits
Saving turtle-slits-oiii-080-060-bin016.fits
Saving turtle-slits-oiii-080-060-bin032.fits
Saving turtle-slits-oiii-080-060-bin064.fits
Saving turtle-slits-oiii-100-080-bin001.fits
Saving turtle-slits-oiii-100-080-bin002.fits
Saving turtle-slits-oiii-100-080-bin004.fits
Saving turtle-slits-oiii-100-080-bin008.fits
Saving turtle-slits-oiii-100-080-bin016.fits
Saving turtle-slits-oiii-100-080-bin032.fits
Saving turtle-slits-oiii-100-080-bin064.fits
Saving turtle-slits-oiii-120-100-bin001.fits
Saving turtle-slits-oiii-120-100-bin002.fits
Saving turtle-slits-oiii-120-100-bin004.fits
Saving turtle-slits-oiii-120-100-bin008.fits
Saving turtle-slits-oiii-120-100-bin016.fits
Saving turtle-slits-oiii-120-100-bin032.fits
Saving turtle-slits-oiii-120-100-bin064.fits
#+end_example

*** Combine multibin maps

#+BEGIN_SRC python :tangle ../scripts/turtle-multibin-combine.py
  import sys
  from astropy.io import fits
  import numpy as np
  sys.path.append('/Users/will/Work/RubinWFC3/Tsquared')
  from rebin_utils import oversample
  from skimage.morphology import square
  from skimage.filters.rank import modal


  def minify(a, n):
      return a[::n, ::n]


  ELEMENT = square(3)
  def cleanup_mask(mask, n):
      """Eliminate small islands in the mask"""
      m = minify(mask, n).astype(np.uint8)
      m = m & modal(m, ELEMENT)
      return oversample(m, n).astype(bool)

      
  try: 
      prefix, minw_scale = sys.argv[1], float(sys.argv[2])
  except:
      print('Usage:', sys.argv[0], 'FITSFILE_PREFIX MINIMUM_WEIGHT [COARSE_WEIGHT]')
      sys.exit()

  try:
      minw_coarse = float(sys.argv[3])
  except IndexError:
      minw_coarse = None

  nlist = [1, 2, 4, 8, 16, 32, 64]
  minweights = [0.5, 1.0, 2.0, 4.0, 8.0, 8.0, 8.0]
  if minw_coarse is not None:
      minweights[-1] = minw_coarse
  outim = np.zeros((512, 512))
  for n, minw in reversed(list(zip(nlist, minweights))):
      fn = '{}-bin{:03d}.fits'.format(prefix, n)
      hdulist = fits.open(fn)
      im = hdulist['scaled'].data
      hdr = hdulist['scaled'].header
      w = hdulist['weight'].data
      # m = cleanup_mask(w*im >= minw*minw_scale, n)
      m = np.isfinite(w) & (w > 0.0) & np.isfinite(im) & (im > 0.0)
      outim[m] = im[m]
  fits.PrimaryHDU(header=hdr, data=outim).writeto(prefix + '-multibin.fits', overwrite=True)
#+END_SRC

#+BEGIN_SRC sh :results silent :dir ..
ranges='+030+040 +020+030 +010+020 +000+010 -010+000 -020-010 -030-020 -040-030 -050-040 -060-050 -070-060 -080-070 -090-080'
for vrange in $ranges -allvels; do
    python scripts/turtle-multibin-combine.py data/maps/turtle-slits-ha$vrange 0.0001 0.0
    python scripts/turtle-multibin-combine.py data/maps/turtle-slits-nii$vrange 0.0001 0.0
done
#+END_SRC


And the extra ones
#+BEGIN_SRC sh :results silent :dir ..
ranges='+040+050 -100-090 -110-100'
for vrange in $ranges; do
    python scripts/turtle-multibin-combine.py data/maps/turtle-slits-ha$vrange 0.0001 0.0
    python scripts/turtle-multibin-combine.py data/maps/turtle-slits-nii$vrange 0.0001 0.0
done
#+END_SRC

#+BEGIN_SRC sh :results silent :dir ..
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  for vrange in $ranges; do
      python scripts/turtle-multibin-combine.py data/maps20/turtle-slits-ha$vrange 0.0001 0.0
      python scripts/turtle-multibin-combine.py data/maps20/turtle-slits-nii$vrange 0.0001 0.0
  done
#+END_SRC

#+BEGIN_SRC sh :results silent :dir ..
  ranges='+040+060 +020+040 +000+020 -020+000 -040-020 -060-040 -080-060 -100-080 -120-100'
  for vrange in $ranges; do
      python scripts/turtle-multibin-combine.py data/maps-oiii-20/turtle-slits-oiii$vrange 0.0001 0.0
  done
#+END_SRC

*** Load PV images into ds9

Central velocities in [O III] - 20 km/s channels
#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-020+000-multibin.fits
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-040-020-multibin.fits
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-060-040-multibin.fits
#+END_SRC

#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-080-060-multibin.fits
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-100-080-multibin.fits
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-120-100-multibin.fits
#+END_SRC

#+BEGIN_SRC sh :dir ../data/maps-oiii-20 :results silent
  DS9=velmaps
  xpaset -p $DS9 rgb red
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+040+060-multibin.fits
  xpaset -p $DS9 rgb green
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+020+040-multibin.fits
  xpaset -p $DS9 rgb blue
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii+000+020-multibin.fits
#+END_SRC


After doing "copy" on the contours we want, we can put them on each frame as follows:
#+begin_src sh :results silent
  DS9=velmaps
  xpaset -p $DS9 contour paste wcs red 1
  xpaset -p $DS9 frame next
#+end_src

The ds9 save files are:
+ [[file:~/Dropbox/Teresa-Turtle/data/maps/turtle-ha-maps.bck]]
+ [[file:~/Dropbox/Teresa-Turtle/data/maps/turtle-nii-maps.bck]]

Figures are in
+ [[file:~/Dropbox/Teresa-Turtle/figs/Screenshot%20turtle-ha-maps.png]]
+ [[file:~/Dropbox/Teresa-Turtle/figs/Screenshot%20turtle-nii-maps.png]]


*** Load up PV images of [O III] results

Use a dedicated DS9 instance
#+begin_src sh :results silent
  open -n -a SAOImageDS9 --args -title velmaps
#+end_src

+ This gets 9 isovel images with 20 km/s width
  + It labels each with the v range
  + And adds the contours of the median image
#+begin_src sh :results silent :dir ../data/maps-oiii-20 
  DS9=velmaps
  ranges='-120-100 -100-080 -080-060 -060-040 -040-020 -020+000 +000+020 +020+040 +040+060'
  for vrange in $ranges; do
      xpaset -p $DS9 frame new
      xpaset -p $DS9 contour no
      xpaset -p $DS9 fits $PWD/turtle-slits-oiii${vrange}-multibin.fits
      xpaset -p $DS9 contour paste wcs red 1
      echo "fk5; text 16:44:28.9973 +23:47:38.458 # color=black text={$vrange}" | xpaset $DS9 regions
  done
#+end_src


Position of slits
#+begin_src sh :results silent :dir ../data/maps-oiii-20 
  DS9=velmaps
  xpaset -p $DS9 frame new
  xpaset -p $DS9 contour no
  xpaset -p $DS9 fits $PWD/turtle-slits-oiii-040-020.fits[1]
  xpaset -p $DS9 contour paste wcs red 1
#+end_src


*** HST images for comparison
Teresa has some that are suitable, but we want to rescale it to make it more easily compared with our own images (divide by 15 for [O III] should put it on same scale as our median image)
#+begin_src python :results silent :dir ../data
  from astropy.io import fits

  hdu = fits.open("/Users/will/Dropbox/Papers/LL-Objects/NGC6210/HST/astrodrizzled/oiii-ene2008-original.fits")["SCI"]

  hdu.data /= 15.0

  hdu.writeto("hst-oiii-ene2008-rescaled.fits", overwrite=True)
#+end_src


One for [N II] too. 
#+begin_src python :results silent :dir ../data
  from astropy.io import fits

  hdu = fits.open("/Users/will/Dropbox/Papers/LL-Objects/NGC6210/HST/astrodrizzled/MAST_2014-10-09T1938/MAST_2014-10-09T1938/HST/2001336009/hst_11122_10_wfpc2_f658n_wf.fits")["SCI"]

  hdu.data /= 20.01

  hdu.writeto("hst-nii-11122_10-rescaled.fits", overwrite=True)
#+end_src

For Ha we use the ones in the top-level directory.  Only two, so take min to avoid CRs

#+begin_src python :results silent :dir ../data
  import numpy as np
  from astropy.io import fits
  ids = ["am", "bm"]
  hdus = [fits.open(
      f"/Users/will/Dropbox/Papers/LL-Objects/NGC6210/HST/u37b010{_}_drz.fits")["SCI"]
          for _ in ids]


  newdata = np.fmin(hdus[0].data, hdus[1].data)

  fits.PrimaryHDU(
      data=newdata*1.5,
      header=hdus[0].header
  ).writeto("hst-ha-wfc-rescaled.fits", overwrite=True)

#+end_src


#+begin_src python :return out_tab
  import glob
  from astropy.io import fits

  file_list = glob.glob("/Users/will/Dropbox/Papers/LL-Objects/NGC6210/HST/*_drz.fits")

  out_tab = [["Name", "Filter"], None]
  for fitsfile in sorted(file_list):
      hdu = 
      out_tab.append([hdu.header["ROOTNAME"], hdu.header.get("FILTNAM1")])

#+end_src

#+RESULTS:
| Name      | Filter |
|-----------+--------|
| u37b0101m | F437N  |
| u37b0102m | F437N  |
| u37b0103m | F437N  |
| u37b0104m | F487N  |
| u37b0105m | F487N  |
| u37b0106m | F502N  |
| u37b0107m | F502N  |
| u37b0108m | F547M  |
| u37b0109m | F547M  |
| u37b010am | F656N  |
| u37b010bm | F656N  |
| u37b010cm | F375N  |
| u37b010dm | F375N  |
| u39h0701t | F658N  |
| u39h0701t | F658N  |
| u39h0702t | F658N  |
| u4js0601r | F502N  |
| u4js0602r | F502N  |
| u4js0603r | F502N  |
| u4js0604r | F502N  |
| u4js0605m | F502N  |
| u4js0606r | F502N  |
| u4js0607r | F658N  |
| u4js0608r | F658N  |
| u4js0609r | F658N  |
| u4js060ar | F658N  |
| u4js060br | F658N  |
| u4js060cr | F658N  |
| u4js060dr | F555W  |
| u4js060er | F555W  |
| u4js060fr | F555W  |
| u4js060gr | F555W  |
| u4js060hr | F555W  |
| u66b0501r | F502N  |
| u66b0502r | F502N  |
| u66b0503r | F502N  |
| u66b0504r | F658N  |
| u66b0505r | F658N  |
| u66b0506r | F658N  |
| u66b0507r | F555W  |
| u66b0508r | F555W  |
| u8s10401m | F185W  |
| u8s10402m | F185W  |
| u8s10403m | F547M  |
| ua011001m | F502N  |
| ua011002m | F502N  |
| ua011003m | F656N  |
| ua011004m | F656N  |
| ua011005m | F658N  |
| ua011006m | F658N  |
| ua011007m | F658N  |

*** The 20 km/s [N II] and H alpha channels

**** H\alpha 20 km/s
Use a dedicated DS9 instance
#+begin_src sh :results silent
  open -n -a SAOImageDS9 --args -title velmapsha
#+end_src
Median image
#+begin_src sh :results silent :dir ../data/imslit-ha
  DS9=velmapsha
  xpaset -p $DS9 fits $PWD/imslit-median.fits
#+end_src

Position of slits
#+begin_src sh :results silent :dir ../data/maps20 
  DS9=velmapsha
  xpaset -p $DS9 frame new
  xpaset -p $DS9 contour no
  xpaset -p $DS9 fits $PWD/turtle-slits-ha-040-020.fits[2]
  # xpaset -p $DS9 contour paste wcs red 1
#+end_src

Add isovel images

#+begin_src sh :results silent :dir ../data/maps20 
  DS9=velmapsha
  ranges='-120-100 -100-080 -080-060 -060-040 -040-020 -020+000 +000+020 +020+040 +040+060'
  for vrange in $ranges; do
      xpaset -p $DS9 frame new
      xpaset -p $DS9 contour no
      xpaset -p $DS9 fits $PWD/turtle-slits-ha${vrange}-multibin.fits
      xpaset -p $DS9 contour paste wcs red 1
      echo "fk5; text 16:44:28.9973 +23:47:38.458 # color=black text={$vrange}" | xpaset $DS9 regions
  done
#+end_src


**** [N II] 20 km/s
Use a dedicated DS9 instance
#+begin_src sh :results silent
  open -n -a SAOImageDS9 --args -title velmapsnii
#+end_src

Median image
#+begin_src sh :results silent :dir ../data/imslit-ha
  DS9=velmapsnii
  xpaset -p $DS9 frame new
  xpaset -p $DS9 fits $PWD/imslit-median.fits
#+end_src

Position of slits
#+begin_src sh :results silent :dir ../data/maps20 
  DS9=velmapsnii
  xpaset -p $DS9 frame new
  xpaset -p $DS9 contour no
  xpaset -p $DS9 fits $PWD/turtle-slits-nii-040-020.fits[2]
  # xpaset -p $DS9 contour paste wcs red 1
#+end_src

Add contours
#+begin_src sh :results silent
  DS9=velmapsnii
  xpaset -p $DS9 contour paste wcs red 1
#+end_src

#+begin_src sh :results silent :dir ../data/maps20 
  DS9=velmapsnii
  ranges='-120-100 -100-080 -080-060 -060-040 -040-020 -020+000 +000+020 +020+040 +040+060'
  for vrange in $ranges; do
      xpaset -p $DS9 frame new
      xpaset -p $DS9 contour no
      xpaset -p $DS9 fits $PWD/turtle-slits-nii${vrange}-multibin.fits
      xpaset -p $DS9 contour paste wcs red 1
      echo "fk5; text 16:44:28.9973 +23:47:38.458 # color=black text={$vrange}" | xpaset $DS9 regions
  done
#+end_src


** Utility functions
:PROPERTIES:
:header-args: :tangle ../scripts/turtle_utils.py
:ID:       60B2ED5C-7B49-4C33-9A59-EF1E7FBBDDDB
:END:

+ Mainly copied from the Owl Nebula's [[id:D65007F8-669F-441C-9FD5-3AEF8BEA4705][Utility functions]]
+ Do ~C-u C-u C-c C-v C-t~ to tangle all blocks into the module ~turtle_utils.py~ in the [[file:../scripts/]] folder

*** Imports
#+BEGIN_SRC python
import numpy as np
from astropy.wcs import WCS
from astropy.coordinates import SkyCoord
from astropy.wcs.utils import pixel_to_skycoord
from astropy import units as u
from astropy.modeling import models, fitting
from matplotlib import pyplot as plt
import seaborn as sns

VERBOSE = 0
#+END_SRC

*** Data paths
We assume that we are running in the top-level project folder file:../

#+begin_src python
  ORIG_DATA_ROOT = "../Papers/LL-Objects/NGC6210"

  def get_orig_folder(temporada):
      if "2015" in temporada:
          return ORIG_DATA_ROOT + "/Temporada2015"
      else:
          return  ORIG_DATA_ROOT + "/Varias-temporadas"


#+end_src

*** Synthetic slit from reference image: slit_profile()
+ Copied from [[id:28077E60-1BFE-4AD4-8DDE-5C292C252564][Construct the synthetic slit from the reference image]]
+ This uses nearest pixel algorithm - no interpolation at all
+ Slit pixels outside of the image are set to NaN 
#+BEGIN_SRC python
  def slit_profile(ra, dec, image, wcs):
      """
      Find the image intensity for a list of positions (ra and dec)
      """
      xi, yj = wcs.all_world2pix(ra, dec, 0)
      # Find nearest integer pixel
      ii, jj = np.floor(xi + 0.5).astype(int), np.floor(yj + 0.5).astype(int)
      if VERBOSE > 0:
          print(ra[::100], dec[::100])
          print(ii[::100], jj[::100])
      ny, nx = image.shape
      return np.array([image[j, i]
                       if (0 < i < nx and 0 < j < ny)
                       else np.nan
                       for i, j in list(zip(ii, jj))])


#+END_SRC


*** World coords from slit pixels: find_slit_coords()
+ This is based on the Owl Nebula version ([[id:4D50A4AB-80B1-4872-899F-8637EC758AB3][World coords from slit pixels]]) but with the following changes:
  1. ~wa~ applies to the PV image, and ~ij~ applies to the im+slit
     - In previous versions, ~saxis~ had been used for both (with opposite sense)
     - The sense is opposite to previously:
       - ~wa~ is the wavelength axis
       - ~ij~ is the CCD axis perpendicular to slit
  2. Check for case where on-chip binning is not specified in header (needed for 2003 data)
#+begin_src python
  def find_slit_coords(db, hdr, shdr):
      """Find the coordinates of all the pixels along a spectrograph slit

      Input arguments are a dict-like 'db' of hand-measured values (must
      contain 'wa', 'ij', islit' and 'shift') and a FITS headers 'hdr' from
      the image+slit exposure and 'shdr' from a spectrum exposure

      Returns a dict of 'ds' (slit pixel scale), 'PA' (slit position
      angle), 'RA' (array of RA values in degrees along slit), 'Dec'
      (array of Dec values in degrees along slit)

      """

      # Decide on axis order for both spectrum and image. Note that
      # values of 'wa' and 'ij' give the axis that is perpendicular to
      # the slit length (wavelength or position, respectively). Hence we
      # subtract from 3 to get the slit length axis
      jstring_i = str(3 - db['ij'])  # which image (I+S) axis lies along slit
      jstring_s = str(3 - db['wa'])  # which spec (pv) axis lies along slit

      dRA_arcsec = hdr['CD1_'+jstring_i]*3600*np.cos(np.radians(hdr['CRVAL2']))
      dDEC_arcsec = hdr['CD2_'+jstring_i]*3600
      ds = np.hypot(dRA_arcsec, dDEC_arcsec)
      PA = np.degrees(np.arctan2(dRA_arcsec, dDEC_arcsec)) % 360.0

      # Deal with parameters that depend on orientation of the PV image
      if jstring_s == '1':
          # PV slit has spatial axis horizontal in IMAGE coords
          ns = shdr['NAXIS1']
          # Mezcal has used two different ways of specifying on-chip binning
          try:
              # Older way
              spec_binning = shdr['CBIN']
          except KeyError:
              try:
                  # Newer way
                  spec_binning = shdr['CCDXBIN']
              except KeyError:
                  # And the very old data don't have it at all
                  spec_binning = 1
      elif jstring_s == '2':
          # PV slit has spatial axis vertical in IMAGE coords
          ns = shdr['NAXIS2']
          try:
              spec_binning = shdr['RBIN']
          except KeyError:
              try:
                  spec_binning = shdr['CCDYBIN']
              except KeyError:
                  spec_binning = 1
      else:
          raise ValueError('PV slit axis (3 - wa) must be 1 or 2')

      # Pixel coords of each slit pixel on image (in 0-based convention)
      # Deal with parameters that depend on orientation of the I+S image
      if jstring_i == '1':
          # Slit is horizontal in IMAGE coords
          iarr = np.arange(ns) - float(db['shift'])
          jarr = np.ones(ns)*float(db['islit'])
          # Mezcal has used two different ways of specifying on-chip binning
          try:
              # Older way
              image_binning = hdr['CBIN']
          except KeyError:
              try:
                  # Newer way
                  image_binning = hdr['CCDXBIN']
              except KeyError:
                  # And the very old data don't have it at all
                  image_binning = 1
          # correct for difference in binning between the image+slit and the spectrum
          iarr *= spec_binning/image_binning
      elif jstring_i == '2':
          # Slit is vertical in IMAGE coords
          iarr = np.ones(ns)*float(db['islit'])
          jarr = np.arange(ns) - float(db['shift'])
          try:
              image_binning = hdr['RBIN']
          except KeyError:
              try:
                  image_binning = hdr['CCDYBIN']
              except KeyError:
                  image_binning = 1
          jarr *= spec_binning/image_binning
      else:
          raise ValueError('I+S slit axis (3 - ij) must be 1 or 2')

      if db['s'] < 0:
          # Slit pixel axis has opposite sense in I+S and PV
          iarr = iarr[::-1]
          jarr = jarr[::-1]

      print('iarr =', iarr[::100], 'jarr =', jarr[::100])
      # Also correct the nominal slit plate scale
      ds *= spec_binning/image_binning

      # Convert to world coords, using the native frame
      w = WCS(hdr)
      observed_frame = w.wcs.radesys.lower()
      # Note it is vital to ensure the pix2world transformation returns
      # values in the order (RA, Dec), even if the image+slit may have
      # Dec first
      coords = SkyCoord(*w.all_pix2world(iarr, jarr, 0, ra_dec_order=True),
                        unit=(u.deg, u.deg), frame=observed_frame)
      print('coords =', coords[::100])
      print('Binning along slit: image =', image_binning, 'spectrum =', spec_binning)
      # Make sure to return the coords in the ICRS frame
      return {'ds': ds, 'PA': PA,
              'RA': coords.icrs.ra.value,
              'Dec': coords.icrs.dec.value}


#+end_src



*** Tidy up the PV image

+ Remove sky and extraneous border pixels

#+begin_src python
  def subtract_sky_and_trim(data, db, trim=3, margin=10):
      """Assume that pixels within `trim` of edge might be bad, and use
      average sky within margin of edge in spatial direction to define
      the bg
      """
      # convert axis notation from FITS to python convention
      wav_axis = 2 - db["wa"]
      if wav_axis == 0:
          bg = 0.5*(data[:, trim:margin] +
                    data[:, -margin:-trim]).mean(axis=1, keepdims=True)
      else:
          bg = 0.5*(data[trim:margin, :] +
                    data[-margin:-trim, :]).mean(axis=0, keepdims=True)
      # Remove sky background
      newdata = data - bg
      # And only then can we clean up the trim zone
      newdata[:trim, :] = 0.0
      newdata[-trim:, :] = 0.0
      newdata[:, :trim] = 0.0
      newdata[:, -trim:] = 0.0
      return newdata
#+end_src

*** Extract profile along PV slit
+ Add extra continuum since the filter is roughly twice as wide as can fit in the PV spectrum, for which we need:
  - ~bandwidth~ full filter width in angstrom
  - ~linewavs~ list of rest wavelengths of the lines so we know what to avoid
+ [ ] Also should deal with saturated pixels

#+begin_src python
  from astropy.constants import c



  def extract_full_profile_from_pv(spec_hdu, wavaxis, bandwidth, linedict):
      assert(wavaxis in [1, 2]) # wavaxis is in FITS convention
      w = WCS(spec_hdu.header)
      if wavaxis == 1:
          nwav = spec_hdu.header['NAXIS1']
          im = spec_hdu.data[:, :]
          wavs, _ = w.all_pix2world(np.arange(nwav), [0], 0)
      else:
          nwav = spec_hdu.header['NAXIS2']
          im = spec_hdu.data[:, :].T
          _, wavs = w.all_pix2world([0], np.arange(nwav), 0)

      # im should have wavelength as last axis (python convention)
      assert(nwav == im.shape[-1])
      full_profile = im.sum(axis=-1)

      if bandwidth is not None:
          wavmask = np.ones((nwav,)).astype(bool)
          # remove from continuum mask +/- 150 km/s around each line
          for lineid, wav0 in linedict.items():
              vels = 3e5*(wavs - wav0)/wav0
              wavmask = wavmask & (np.abs(vels) > 150.0)

          # broadcast to 2 dimensions
          imwts = np.ones_like(im)*wavmask[None, :]
          av_cont_profile = np.average(im, weights=imwts, axis=-1)
          # find how much extra continuum to add
          dwav = abs(wavs[1] - wavs[0])
          pv_bw = abs(wavs[-1] - wavs[0])
          missing_cont_profile = av_cont_profile*(bandwidth - pv_bw)/dwav
          # Add to the profile summed over the PV bandwidth
          full_profile += missing_cont_profile
      return full_profile


  def extract_slit_profile_from_imslit(data, db, slit_width=1):
      print(db["islit"])
      i1, i2 = int(db["islit"]) - slit_width, int(db["islit"]) + slit_width
      if db["ij"] == 1:
          return data[:, i1:i2].sum(axis=1)
      elif db["ij"] == 2:
          return data[i1:i2, :].sum(axis=0 )
      else:
          raise ValueError("ij must be 1 or 2")


#+end_src


*** Extract spectra for individual lines
+ These are heavily based on the Owl versions, but with changes due swapping ~saxis~ for ~wa~
#+begin_src python
  def extract_profile(data, wcs, wavrest, db, dw=7.0):
      """We don't use this any more"""
      data, bgdata = remove_bg_and_regularize(data, wcs, wavrest, db)
      # pixel limits for line extraction
      lineslice = wavs2slice([wavrest-dw/2, wavrest+dw/2], wcs, db)
      return data[:, lineslice].sum(axis=1), bgdata.sum(axis=1)


  def wavs2slice(wavs, wcs, db):
      """Convert a wavelength interval `wavs` (length-2 sequence) to a slice of the relevant axis`"""
      assert len(wavs) == 2
      isT = db['wa'] == 2
      if isT:
          _, xpixels = wcs.all_world2pix([0, 0], wavs, 0)
      else:
          xpixels, _ = wcs.all_world2pix(wavs, [0, 0], 0)
      print('Wav:', wavs, 'Pixel:', xpixels)
      i1, i2 = np.maximum(0, (xpixels+0.5).astype(int))
      return slice(min(i1, i2), max(i1, i2))


  def extract_line_and_regularize(data, wcs, wavrest, db,
                                  dw=10.0, dwbg_in=7.0, dwbg_out=10.0):
      '''
      Transpose data if necessary, and then subtract off the continuum
      (blue and red of line, inner width `dwbg_in`, outer width
      `dwbg_out`) and restrict to window (width `dw`) around line
      center.  Returns cont-subtracted PV array (2d), cont array (2d),
      and wavs array (1d)
      '''
      isT = db['wa'] == 2
      # Make sure array axis order is (position, wavelength)
      if isT:
          data = data.T
          nwav = wcs.pixel_shape[1]
          _, wavs = wcs.all_pix2world([0], np.arange(nwav), 0)
      else:
          nwav = wcs.pixel_shape[0]
          wavs, _ = wcs.all_pix2world(np.arange(nwav), [0], 0)

      # pixel limits for blue, red bg extraction
      bslice = wavs2slice([wavrest-dwbg_out/2, wavrest-dwbg_in/2], wcs, db)
      rslice = wavs2slice([wavrest+dwbg_in/2, wavrest+dwbg_out/2], wcs, db)
      # extract backgrounds on blue and red sides
      bgblu = np.nanmean(data[:, bslice], axis=1)
      bgred = np.nanmean(data[:, rslice], axis=1)
      # take weighted average, accounting for cases where the bg region
      # does not fit in the image
      weight_blu = data[:, bslice].size
      weight_red = data[:, rslice].size
      print('Background weights:', weight_blu, weight_red)
      if weight_blu and weight_red:
          bg = (bgblu*weight_blu + bgred*weight_red)/(weight_blu + weight_red)
      elif weight_blu:
          bg = bgblu
      elif weight_red:
          bg = bgred
      else:
          raise ValueError("No valid red or blue BG found")
    

      # pixel limits for entire window
      wslice = wavs2slice([wavrest-dw/2, wavrest+dw/2], wcs, db)
      # restrict to just this window
      data = data[:, wslice]
      # and actually subtract the continuum
      bgdata = np.zeros_like(data)
      bgdata += bg[:, None]

      return data - bgdata, bgdata, wavs[wslice]
#+end_src

#+RESULTS:
: None

*** Make WCS for the PV images
#+BEGIN_SRC python
  def make_slit_wcs(db, slit_coords, wavs, j0):

      #
      # First, wavelength axis, which is easy
      #
      dwav = wavs[1] - wavs[0]
      wav0 = wavs[0]
      wavpix0 = 1

      #
      # Second, find the displacement scale and ref point from the slit_coords
      #
      # The slit_coords should already be in ICRS frame
      c = SkyCoord(slit_coords['RA'], slit_coords['Dec'], unit=u.deg)
      # Find vector of separations between adjacent pixels
      seps = c[:-1].separation(c[1:])
      # Ditto for the position angles
      PAs = c[:-1].position_angle(c[1:])
      # Check that they are all the same as the first one
      assert(np.allclose(seps/seps[0], 1.0))
      # assert(np.allclose(PAs/PAs[0], 1.0, rtol=1.e-4))
      # Then use the first one as the slit pixel size and PA
      ds, PA, PA_deg = seps[0].deg, PAs.mean().rad, PAs.mean().deg
      # And for the reference values too
      RA0, Dec0 = c[0].ra.deg, c[0].dec.deg

      #
      # Now make a new shiny output WCS, constructed from scratch
      #
      w = WCS(naxis=3)

      # Make use of all the values that we calculated above
      w.wcs.crpix = [wavpix0, 1, 1]
      w.wcs.cdelt = [dwav, ds, ds]
      w.wcs.crval = [wav0, RA0, Dec0]
      # PC order is i_j = [[1_1, 1_2, 1_3], [2_1, 2_2, 2_3], [3_1, 3_2, 3_3]]
      w.wcs.pc = [[1.0, 0.0, 0.0],
                  [0.0, np.sin(PA), -np.cos(PA)],
                  [0.0, np.cos(PA), np.sin(PA)]]

      #
      # Finally add in auxillary info
      #
      w.wcs.radesys = 'ICRS'
      w.wcs.ctype = ['AWAV', 'RA---TAN', 'DEC--TAN']
      w.wcs.specsys = 'TOPOCENT'
      w.wcs.cunit = [u.Angstrom, u.deg, u.deg]
      w.wcs.name = 'TopoWav'
      w.wcs.cname = ['Observed air wavelength', 'Right Ascension', 'Declination']

      # Check the new pixel values
      npix = len(slit_coords['RA'])
      check_coords = pixel_to_skycoord(np.arange(npix), [0]*npix, w, 0)
      # These should be the same as the ICRS coords in slit_coords
      print('New coords:', check_coords[::100])
      print('Displacements in arcsec:', check_coords.separation(c).arcsec[::100])
      # 15 Sep 2015: They seem to be equal to within about 1e-2 arcsec

      #
      # And a simple version with slit offsets in arcsec
      #
      w2 = WCS(naxis=2)
      w2.wcs.crpix = [wavpix0, j0+1]
      w2.wcs.cdelt = [dwav, ds]
      w2.wcs.crval = [wav0, 0.0]
      w2.wcs.ctype = ['LINEAR', 'LINEAR']

      return w, w2
#+END_SRC
*** Fit Chebyshev polynomial
#+begin_src python
  def fit_cheb(x, y, npoly=3, mask=None):
      """Fits a Chebyshev poly to y(x) and returns fitted y-values"""
      fitter = fitting.LinearLSQFitter()
      p_init = models.Chebyshev1D(npoly, domain=[x.min(), x.max()])
      if mask is None:
          mask = np.ones_like(x).astype(bool)
      p = fitter(p_init, x[mask], y[mask])
      if VERBOSE > 0:
          print(p)
      return p(x)


#+end_src

*** Plot utilities
#+begin_src python
  def make_three_plots(spec, calib, prefix,
                       slit_points=None, niirat=None, neighbors=None, db=None, sdb=None, linelabel="H$\alpha$"):
      assert spec.shape == calib.shape
      fig, axes = plt.subplots(3, 1)

      if slit_points is None:
          ypix = np.arange(len(calib))
          xlabel = "Slit pixel"
          xlim = None
      else:
          ypix = slit_points
          xlabel = "Slit position, arcsec"
          xlim = -80, 80

      xlim = xlim or (ypix.min(), ypix.max())

      # vmax = np.percentile(calib, 95) + 2*calib.std()
      vmax = 20.0
      vmin = -0.01
      ratio = spec/calib

      alpha = 0.8

      # First, plot two profiles against each other to check for zero-point offsets
      # axes[0].plot(calib, spec/ratio_fit, '.', alpha=alpha)
      axes[0].plot(calib, spec, '.', alpha=alpha)
      axes[0].plot([vmin, vmax], [vmin, vmax], '-', alpha=alpha)
      axes[0].set_xlim(vmin, vmax)
      axes[0].set_ylim(vmin, vmax)
      axes[0].set_xlabel('Calibration Image')
      axes[0].set_ylabel('Uncorrected Integrated Spectrum')
      axes[0].set_xscale('symlog', linthreshx=0.01)
      axes[0].set_yscale('symlog', linthreshy=0.01)

      # Second, plot each against slit pixel to check spatial offset
      axes[1].plot(ypix, spec, alpha=alpha, lw=1,
                   label='Integrated Spectrum')
      axes[2].plot(ypix, spec/np.nanmax(calib), alpha=alpha, lw=1,
                   label='Integrated Spectrum')
      axes[1].plot(ypix, calib, alpha=alpha, label='Calibration Image')
      axes[2].plot(ypix, calib/np.nanmax(calib), alpha=alpha, label='Calibration Image')
      if neighbors is not None:
          for nb, calib_nb in neighbors.items():
              lw = 0.5 + 0.1*nb
              label = f"Slit $\Delta x = {nb:+1d}$"
              axes[1].plot(ypix, calib_nb,
                           alpha=0.3*alpha, lw=lw, color="k", label=label)
              axes[2].plot(ypix, calib_nb/np.nanmax(calib_nb),
                           alpha=0.3*alpha, lw=lw, color="k", label=label)
      # axes[1].plot(ypix, spec/ratio_fit, alpha=alpha, lw=1.0,
      #              label='Corrected Integrated Spectrum')
      axes[1].set_xlim(*xlim)
      axes[1].set_ylim(vmin, vmax)
      axes[1].legend(fontsize='xx-small', loc='upper right')
      axes[1].set_xlabel(xlabel)
      axes[1].set_ylabel('Profile (absolute log scale)')
      axes[1].set_yscale('symlog', linthreshy=0.01)

      # # Third, plot ratio to look for spatial trends
      # axes[2].plot(ypix, ratio, alpha=alpha)
      # axes[2].plot(ypix, ratio_fit, alpha=alpha)
      # if niirat is not None:
      #     axes[2].plot(ypix, niirat, 'b', lw=0.5, alpha=0.5)
      axes[2].set_xlim(-40, 40)
      axes[2].set_ylim(-0.05, 1.05)
      axes[2].set_xlabel(xlabel)
      # axes[2].set_ylabel('Ratio: Spec / Calib')
      axes[2].set_ylabel('Profile (relative linear scale)')

      info = ""
      if db is not None:
          # Add some info to the graphs
          info += fr"{linelabel} slit {db['id']:02d}" + "\n"
          info += f"PV: {db['spec']}" +"\n"
          info += f"I+S: {db['imslit']}" + "\n"
          info += f"Date: {db['run']}, t = {db['t']} s" + "\n"
      if sdb is not None:
          info += fr"Slit PA = ${sdb['PA']:.1f}^\circ$, ds = {sdb['ds']:.2f} arcsec" + "\n"
      if info:
          axes[0].text(0.95, 0.05, info,
                       fontsize="small",
                       ha="right", va="bottom", transform=axes[0].transAxes)
      fig.set_size_inches(5, 8)
      fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)
      fig.savefig(prefix+'.png', dpi=300)
      plt.close(fig)

      return None


#+end_src

#+RESULTS:
: None

* Teresa's tables
** H alpha
So, she has 11 positions missing
*** 2015 Ha (11 positions)
| #       |      RA |     Dec | dataset | helio corr |  NX |  NY | xpixscale | jcenter | ufiddle | fluxfiddle | "True File"          |
|---------+---------+---------+---------+------------+-----+-----+-----------+---------+---------+------------+----------------------|
| east871 | -0.8712 | 22.0212 |       1 |     -20.54 | 300 | 373 |     0.351 |     219 |       0 |         20 | spec0116-ha-inv.fits |
| east612 | -0.7104 | 22.1004 |       1 |     -20.45 | 300 | 373 |     0.351 |     225 |       0 |         30 | spec0110-ha-inv.fits |
| east300 |    -0.3 | -7.5708 |       1 |     -20.41 | 300 | 373 |     0.352 |     145 |       0 |          1 | spec0031-ha-inv.fits |
| east148 |  -0.096 | -8.5932 |       1 |     -20.49 | 300 | 373 |     0.352 |     144 |       0 |          1 | spec0037-ha-inv.fits |
| west069 |  0.0696 | -7.1784 |       1 |     -20.55 | 300 | 373 |     0.352 |     150 |       0 |          1 | spec0043-ha-inv.fits |
| west300 |     0.3 | -6.6456 |       1 |     -20.59 | 300 | 373 |     0.352 |     150 |       0 |          1 | spec0049-ha-inv.fits |
| west492 |   0.492 | -7.1532 |       1 |     -20.63 | 300 | 373 |     0.352 |     144 |       0 |          1 | spec0057-ha-inv.fits |
| west528 |   0.528 | 22.9752 |       1 |     -20.47 | 300 | 373 |     0.351 |     224 |       0 |          1 | spec0173-ha-inv.fits |
| west684 |   0.684 | 22.0284 |       1 |     -20.65 | 300 | 373 |     0.351 |     220 |       0 |          1 | spec0124-ha-inv.fits |
| west873 |  0.8736 | 21.0384 |       1 |     -20.55 | 300 | 373 |     0.351 |     215 |       0 |          1 | spec0179-ha-inv.fits |
| west120 |  1.2024 | 21.5748 |       1 |      -20.6 | 300 | 373 |     0.351 |     220 |       0 |          1 | spec0186-ha-inv.fits |

+ Imported from file:~/Dropbox/Papers/LL-Objects/NGC6210/Temporada2015/SPMha/star-ha.csv
+ Constant columns removed:
  + lamrest :: 6562.8
  + lam0 :: 6557
  + lamscale :: 0.043752133
  + d vel :: 2

*** 1998 \to 2013 Ha (8 positions)
| #       |      RA |     Dec | dataset | helio corr |  NX |  NY | ypixscale | jcenter | ufiddle | fluxfiddle | "True File"                   |
|---------+---------+---------+---------+------------+-----+-----+-----------+---------+---------+------------+-------------------------------|
| east087 | -1.0968 |   -5.76 |       1 |      -3.23 | 300 | 101 |     0.624 |      55 |       0 |          1 | spec135-crop-ha.fits          |
| east040 | -0.6264 | -10.476 |       1 |       -2.9 | 300 | 101 |     0.625 |      55 |       0 |          1 | spec119-crop-ha.fits          |
| east015 |  -0.372 |  -9.612 |       1 |      -2.84 | 300 | 101 |     0.626 |      55 |       0 |          1 | spec116-crop-ha.fits          |
| west005 |  -0.168 |   -9.72 |       1 |      -2.79 | 300 | 101 |     0.625 |      55 |       0 |          1 | spec112-crop-ha.fits          |
| west027 |  0.0432 |  19.404 |       2 |       2.44 | 300 | 101 |     0.351 |     130 |       0 |          1 | spec112-2crop-ha-binning.fits |
| west053 |  0.3048 | -10.116 |       1 |      -2.97 | 300 | 101 |     0.625 |      55 |       0 |          1 | spec122-crop-ha.fits          |
| west084 |  0.6168 |  -9.612 |       1 |      -3.04 | 300 | 101 |     0.624 |      55 |       0 |          1 | spec125-crop-ha.fits          |
| west122 |  0.9936 |  -8.784 |       1 |      -3.17 | 300 | 101 |     0.623 |      55 |       0 |          1 | spec130-crop-ha.fits          |
